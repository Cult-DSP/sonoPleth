# Real-Time Spatial Audio Engine – Agent Overview

## Implementation Decisions (Updated 2026-02-26)

> These decisions were made during initial planning and override any conflicting
> assumptions in the agent sub-documents. Sub-documents remain useful for
> detailed design guidance but should be read in light of the notes below.

### Development Model – Sequential, Not Concurrent

The agent architecture segments responsibilities but **agents are implemented
one at a time, sequentially**, not in parallel. Each agent is:

1. Implemented based on the logical architecture order.
2. Tested in isolation and in integration with previously completed agents.
3. Documented (this file and the agent's own `.md` are updated).
4. The updated docs are handed to a **new context window** for the next agent task.

This ensures each step is stable before the next begins.

### Audio Backend – AlloLib

Continue using **AlloLib's AudioIO** (already a dependency via
`thirdparty/allolib`). No PortAudio or JACK for v1.

### Build System & File Location

- The real-time engine lives in **`spatial_engine/realtimeEngine/`**.
- It gets its own `CMakeLists.txt` (mirroring `spatialRender/CMakeLists.txt`).
- Links against the same AlloLib in `thirdparty/allolib`.

### Code Reuse Strategy – Header-Based Core, Reference Old CPP

- The real-time engine's core logic goes into **header files** (`.hpp`) inside
  `spatial_engine/realtimeEngine/`.
- Code may be **copied and adapted** from the offline `SpatialRenderer.cpp`
  (DBAP coordinate transforms, elevation sanitization, direction interpolation,
  LFE routing, gain logic, etc.).
- The old offline `.cpp` file stays untouched — the headers reference it in
  comments for provenance but do not `#include` it.
- Goal: the offline renderer continues to compile and work exactly as before.

### GUI – Dedicated Realtime GUI Entry (PySide6)

- Keep PySide6 (Qt) and **do not switch to ImGui** (ImGui remains reference-only).
- Do **not** bloat the existing offline GUI. Create a parallel realtime entry:
  - `gui/realtimeGUI/realtimeGUI.py` (new)
  - optional `gui/realtimeGUI/` folder with panels + `realtime_runner.py`
- The realtime GUI launches `runRealtime.py` via `QProcess` (same pattern as `pipeline_runner.py`).

### Runtime Control Plane (stability priority)

- Prefer AlloLib **`al::Parameter` / `ParameterBundle` + `ParameterServer` (OSC)** for live runtime controls.
- GUI sends OSC updates; engine reads parameters in a RT-safe way (audio thread reads, heavy work on main/control thread).
- This control-plane contract is intended to **survive the later pipeline refactor**.

### Python Entry Point – `runRealtime.py`

- **`runRealtime.py`** at the project root mirrors `runPipeline.py` — it
  accepts the **same inputs** (ADM WAV file or LUSID package directory +
  speaker layout) and runs the **same preprocessing pipeline** (ADM extract
  → parse to LUSID → write scene.lusid.json).
- For **ADM sources**: preprocessing writes scene.lusid.json only (no stem
  splitting), then launches the C++ engine with `--adm` pointing to the
  original multichannel WAV for direct streaming.
- For **LUSID packages**: validates and launches with `--sources` pointing
  to the mono files folder.
- Two pipeline entry points:
  - `run_realtime_from_ADM(source_adm, layout)` — ADM preprocessing + direct streaming
  - `run_realtime_from_LUSID(package_dir, layout)` — direct launch from mono files
- CLI uses `checkSourceType()` to auto-detect ADM vs LUSID input, same
  pattern as `runPipeline.py`.
- No `--channels` parameter — channel count is derived from the speaker
  layout by the C++ engine's `Spatializer::init()`.
- Keeps everything **segmented** — the offline pipeline is never touched, and
  `runRealtime.py` can be debugged independently.
- The Qt GUI will call `runRealtime.py` via `QProcess` (same pattern as
  `pipeline_runner.py` calls `runPipeline.py`).

### Target Milestone – Replicate Pipeline in Real-Time

The first working version must:

1. Accept the same inputs as the offline pipeline: **ADM WAV file** or
   **LUSID package directory** + speaker layout JSON. Run the same
   preprocessing (ADM extract → parse → package) before launching.
2. Parse the LUSID scene (reuse existing `LUSID/` Python package — this part
   is straightforward and safe).
3. Stream the mono stems from disk (double-buffered, real-time safe).
4. Spatialize with DBAP in the AlloLib audio callback (reusing proven gain
   math from `SpatialRenderer.cpp`).
5. Route LFE to subwoofer channels (same logic as offline).
6. Output to hardware speakers via AlloLib AudioIO.
7. Be launchable from `runRealtime.py` and from the Qt GUI.

This effectively **replicates the offline pipeline but plays back in
real-time** instead of writing a WAV file.

### Agent Implementation Order

Based on the architecture's data-flow dependencies, the planned order is:

| Phase | Agent(s)                  | Why this order                                        | Status      |
| ----- | ------------------------- | ----------------------------------------------------- | ----------- |
| 1     | **Backend Adapter**       | Need audio output before anything else is audible     | ✅ Complete |
| 2     | **Streaming**             | Need audio data to feed the mixer                     | ✅ Complete |
| 3     | **Pose and Control**      | Need positions before spatialization                  | ✅ Complete |
| 4     | **Spatializer (DBAP)**    | Core mixing — depends on 1-3                          | ✅ Complete |
| —     | **ADM Direct Streaming**  | Optimization: skip stem splitting for ADM sources     | ✅ Complete |
| 5     | **LFE Router**            | ~~Runs in audio callback after spatializer~~          | ⏭️ Skipped  |
| 6     | **Compensation and Gain** | Loudspeaker/sub mix sliders + focus auto-compensation | ✅ Complete |
| 7     | **Output Remap**          | Final channel shuffle before hardware                 | ✅ Complete |
| —     | **Audio Scan Toggle**     | `scan_audio=False` default in `runRealtime.py`        | ✅ Complete |
| 8     | **Threading and Safety**  | Harden all inter-thread communication                 | ✅ Complete |

9 - update init.sh and files in src/config to handle the updated realtime engine and tooling. ✅ Complete
| 10 | **GUI Agent** | PySide6 realtimeGUI (separate entry), QProcess→runRealtime.py, ParameterServer control plane | ✅ Complete |

11 - update main project read me and relevant documentation

> **Note:** Phases 1-4 together form the minimum audible prototype (sound
> comes out of speakers). Phases 5-7 add correctness. Phase 8 hardens
> reliability. Phase 9 adds the user interface.

### Next Major Task (after Phase 10 prototype): Pipeline Refactor (C++-first realtime)

- Promote the C++ realtime executable to the canonical entrypoint (Python becomes optional wrapper/tooling).
- Keep Python for LUSID transcoding + batch prep initially; evaluate rewrite of runtime-prep into C/C++ once the GUI prototype is stable.
- Preserve the control plane contract (parameter names + ranges) so UI work is not thrown away.

### Phase 10 Completion Log (GUI Agent) — ✅ Complete (Feb 26 2026)

**Design doc:** `internalDocsMD/realtime_planning/agentDocs/agent_gui_UPDATED_v3.md`
**AlloLib IPC reference:** `internalDocsMD/realtime_planning/agentDocs/allolib_parameters_reference.md`

#### Decisions locked

| Decision                 | Detail                                                                                          |
| ------------------------ | ----------------------------------------------------------------------------------------------- |
| Framework                | PySide6 (no ImGui)                                                                              |
| Entry point              | `realtimeMain.py` at project root — standalone window, NOT a tab in `gui/main.py`               |
| Process launch           | `runRealtime.py` via `QProcess` (mirrors PipelineRunner pattern)                                |
| IPC / runtime controls   | AlloLib `al::Parameter` + `al::ParameterServer` (OSC, port 9009). GUI sends via `python-osc`    |
| Pause/Play               | C++ changes in-scope: `config.paused` atomic + callback silence branch + ParameterServer wiring |
| `--remap` passthrough    | Add to `runRealtime.py` and `_launch_realtime_engine()`                                         |
| `--osc_port` passthrough | Add to `runRealtime.py` and `_launch_realtime_engine()`                                         |
| Stylesheet               | Reuse `gui/styles.qss`                                                                          |
| Visualization            | Deferred                                                                                        |

#### Files to create (GUI)

| File                                                        | Purpose                                                                               |
| ----------------------------------------------------------- | ------------------------------------------------------------------------------------- |
| `realtimeMain.py`                                           | Project-root launcher — loads styles.qss, creates `RealtimeWindow`, runs QApplication |
| `gui/realtimeGUI/__init__.py`                               | Package marker                                                                        |
| `gui/realtimeGUI/realtimeGUI.py`                            | `RealtimeWindow` — main QWidget, assembles panels                                     |
| `gui/realtimeGUI/realtime_runner.py`                        | `RealtimeRunner` + `RealtimeConfig` — QProcess wrapper, OSC sender, state machine     |
| `gui/realtimeGUI/realtime_panels/__init__.py`               | Package marker                                                                        |
| `gui/realtimeGUI/realtime_panels/RealtimeInputPanel.py`     | Source/layout/remap/buffer/scan inputs                                                |
| `gui/realtimeGUI/realtime_panels/RealtimeControlsPanel.py`  | Live sliders + auto comp toggle                                                       |
| `gui/realtimeGUI/realtime_panels/RealtimeLogPanel.py`       | Stdout/stderr console, 2000-line cap                                                  |
| `gui/realtimeGUI/realtime_panels/RealtimeTransportPanel.py` | Start/Stop/Kill/Restart/Pause/Play + status pill                                      |

#### Files to modify (C++ engine + Python)

| File                                                    | Change                                                                                                                              |
| ------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |
| `spatial_engine/realtimeEngine/src/RealtimeTypes.hpp`   | Add `std::atomic<bool> paused{false}` + doc comment                                                                                 |
| `spatial_engine/realtimeEngine/src/main.cpp`            | Add ParameterServer, 6 al::Parameter objects, registerChangeCallbacks, `--osc_port` CLI flag, `pendingAutoComp` flag, shutdown call |
| `spatial_engine/realtimeEngine/src/RealtimeBackend.hpp` | Add pause guard at top of `processBlock()`                                                                                          |
| `runRealtime.py`                                        | Add `remap_csv` + `osc_port` args to `_launch_realtime_engine()`; update CLI parsing                                                |
| `requirements.txt`                                      | Add `python-osc`                                                                                                                    |

#### Implementation order (within Phase 10)

1. **C++ engine changes first** — `RealtimeTypes.hpp` + `RealtimeBackend.hpp` + `main.cpp` (ParameterServer + pause). Build and verify OSC control works from CLI (`oscsend` or python-osc test script).
2. **`runRealtime.py` updates** — add `--remap` and `--osc_port` passthrough. Test CLI.
3. **`RealtimeRunner` + `RealtimeConfig`** — QProcess wrapper, OSC sender, state machine. Test independently.
4. **Panels** — InputPanel, TransportPanel, ControlsPanel, LogPanel (in that order — each adds on top of the previous).
5. **`RealtimeWindow` + `realtimeMain.py`** — assemble panels, wire signals, launch.
6. **End-to-end test** against testing checklist in `agent_gui_UPDATED_v3.md §9`.

#### What was built

**C++ engine changes:**

| File                                                    | Change                                                                                                                                                                                                                                                                                                               |
| ------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `spatial_engine/realtimeEngine/src/RealtimeTypes.hpp`   | Added `std::atomic<bool> paused{false}` to `RealtimeConfig` with full threading doc comment and memory-ordering table entry                                                                                                                                                                                          |
| `spatial_engine/realtimeEngine/src/RealtimeBackend.hpp` | Added pause guard at top of `processBlock()` — relaxed load, zero channels + early return, RT-safe                                                                                                                                                                                                                   |
| `spatial_engine/realtimeEngine/src/main.cpp`            | Phase 10 banner; `al::Parameter` × 4 + `al::ParameterBool` × 2; `al::ParameterServer` on `--osc_port` (default 9009); `registerChangeCallback` for all 6 params; `pendingAutoComp` flag + main-loop consumer; `--focus` CLI flag; `paramServer.stopServer()` first in shutdown; status line now shows PAUSED/PLAYING |

**Python changes:**

| File               | Change                                                                                                                                                                                                                                         |
| ------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `runRealtime.py`   | `remap_csv=None` + `osc_port=9009` kwargs in `_launch_realtime_engine()`; `--remap` + `--osc_port` appended to `cmd`; threaded through `run_realtime_from_ADM()` + `run_realtime_from_LUSID()`; CLI `--remap` / `--osc_port` named-arg parsing |
| `requirements.txt` | Added `python-osc`                                                                                                                                                                                                                             |

**GUI files created:**

| File                                                        | Purpose                                                                                                                                                                                  |
| ----------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `realtimeMain.py`                                           | Project-root launcher — loads `gui/styles.qss`, creates `RealtimeWindow`, runs `QApplication`                                                                                            |
| `gui/realtimeGUI/__init__.py`                               | Package marker (one line)                                                                                                                                                                |
| `gui/realtimeGUI/realtimeGUI.py`                            | `RealtimeWindow(QMainWindow)` — header bar, scroll area, assembles all four panels, wires runner signals                                                                                 |
| `gui/realtimeGUI/realtime_runner.py`                        | `RealtimeConfig` dataclass; `RealtimeRunnerState` enum; `DebouncedOSCSender` (40 ms QTimer); `RealtimeRunner(QObject)` — QProcess + `SimpleUDPClient`, full state machine, graceful stop |
| `gui/realtimeGUI/realtime_panels/__init__.py`               | Package marker                                                                                                                                                                           |
| `gui/realtimeGUI/realtime_panels/RealtimeInputPanel.py`     | Source/layout/remap/buffer/scan inputs; inline ADM vs LUSID auto-detection hint; browse dialogs                                                                                          |
| `gui/realtimeGUI/realtime_panels/RealtimeTransportPanel.py` | Start/Stop/Kill/Restart/Pause/Play; colour-coded status pill; Copy Command; OSC port label                                                                                               |
| `gui/realtimeGUI/realtime_panels/RealtimeControlsPanel.py`  | `_ParamRow` (slider ↔ spinbox, debounced vs immediate sends); gain/focus/spkMix/subMix rows + auto-comp checkbox; `reset_to_defaults()` on each Start                                    |
| `gui/realtimeGUI/realtime_panels/RealtimeLogPanel.py`       | `QPlainTextEdit` (monospace, read-only); 2000-line cap; auto-scroll; Clear button                                                                                                        |

**Build result:** `make -j4` → zero errors. `--help` output confirms `--focus` and `--osc_port` flags. All Python imports verified clean.

---

### Phase 1 Completion Log (Backend Adapter)

**Files created:**

| File                                                    | Purpose                                                                                                                                                                                                                                                 |
| ------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `spatial_engine/realtimeEngine/CMakeLists.txt`          | Build system — links AlloLib + Gamma, shares `JSONLoader`/`LayoutLoader`/`WavUtils` from `../src/`                                                                                                                                                      |
| `spatial_engine/realtimeEngine/src/RealtimeTypes.hpp`   | Shared data types: `RealtimeConfig` (device settings, paths, atomic gain/playback flags) and `EngineState` (frame counter, playback time, CPU load, xrun count)                                                                                         |
| `spatial_engine/realtimeEngine/src/RealtimeBackend.hpp` | Agent 8 implementation — wraps AlloLib `AudioIO` with `init()`/`start()`/`stop()`/`shutdown()` lifecycle, static C-style callback dispatches to `processBlock()`, CPU load clamping                                                                     |
| `spatial_engine/realtimeEngine/src/main.cpp`            | CLI entry point — parses `--layout`/`--scene`/`--sources` + optional args, runs monitoring loop with status display, handles SIGINT for clean shutdown                                                                                                  |
| `runRealtime.py`                                        | Python launcher — mirrors `runPipeline.py` with same input types (ADM WAV or LUSID package). Runs preprocessing pipeline, then launches C++ executable. `run_realtime_from_ADM()` / `run_realtime_from_LUSID()` entry points. Handles Ctrl+C forwarding |

**Build & test results:**

- CMake configures successfully (AlloLib + Gamma link)
- `make -j4` compiles with zero errors
- Binary runs, opens audio device (2-channel test), streams silence for 3 seconds
- SIGINT handler triggers clean shutdown (stop → close → exit 0)
- Frame counter advances correctly (~144k frames in 3s at 48kHz)
- CPU load reports 0.0% (silence — trivial callback)

**What the next phase gets:**

- A working audio callback that currently outputs silence
- `processBlock(AudioIOData&)` is the insertion point for all future agents
- `RealtimeConfig` and `EngineState` are the shared state structs
- `runRealtime.py` is ready to call from the GUI (accepts same inputs as `runPipeline.py`)

### Phase 2 Completion Log (Streaming Agent)

**Files created/modified:**

| File                                                    | Action       | Purpose                                                                                                                                                                                                           |
| ------------------------------------------------------- | ------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `spatial_engine/realtimeEngine/src/Streaming.hpp`       | **Created**  | Agent 1 — double-buffered per-source WAV streaming with background loader thread. Each source gets two 5-second buffers (240k frames at 48kHz). Lock-free audio-thread reads via atomic buffer states.            |
| `spatial_engine/realtimeEngine/src/RealtimeBackend.hpp` | **Modified** | Added `Streaming*` pointer and `setStreaming()`/`cacheSourceNames()` methods. `processBlock()` now reads mono blocks from each source, sums with 1/N normalization × master gain, mirrors to all output channels. |
| `spatial_engine/realtimeEngine/src/main.cpp`            | **Modified** | Now loads LUSID scene via `JSONLoader::loadLusidScene()`, creates `Streaming`, opens all source WAVs, wires into backend, starts loader thread before audio, shuts down in correct order (backend → streaming).   |
| `internalDocsMD/AGENTS.md`                              | **Modified** | Added "Real-Time Spatial Audio Engine" section with architecture, file descriptions, build instructions, streaming design, run example. Updated file structure tree and Future Work.                              |

**Design decisions:**

- **libsndfile access**: Uses `<sndfile.h>` directly (same as `WavUtils.cpp`). Available transitively through Gamma → `find_package(LibSndFile QUIET)` → exported via PUBLIC link. No new dependencies.
- **Per-source double buffers**: Each source gets independent buffers (not a shared multichannel buffer). Simpler, avoids cross-source contention.
- **5-second chunk size** (240k frames): Balances memory (~1.8 MB per source, ~63 MB for 35 sources) against seek frequency. Only needs ~20 loads per source over a 98-second piece.
- **50% preload threshold**: Background thread starts loading the next chunk when playback passes the halfway point of the active buffer. Gives 2.5 seconds of runway before the buffer switch.
- **Single loader thread**: One thread services all sources sequentially. At 2ms poll interval and ~35 sources, worst-case full scan takes <1ms. Sufficient for current source count.
- **Mutable atomics for buffer state**: `stateA`, `stateB`, `activeBuffer` are `mutable` in `SourceStream` because the audio thread may switch buffers during a logically-const `getSample()` call.

**Build & test results:**

- `cmake .. && make -j4` compiles with zero errors
- 35 sources loaded successfully (34 audio objects + LFE), each ~98 seconds (4,703,695 frames at 48kHz)
- Ran for 69.7 seconds with 2 output channels, --gain 0.1
- CPU load: 0.0% (mono sum of 35 sources + memcpy is trivially fast)
- No xruns, no underruns, no file handle leaks
- Clean SIGINT shutdown: backend stops → streaming agent closes all SNDFILE handles → exit 0
- Background loader thread joins cleanly

**What the next phase gets:**

- `StreamingAgent::getBlock(sourceName, startFrame, numFrames, outBuffer)` — lock-free mono block read from any source
- `StreamingAgent::sourceNames()` — list of all loaded source keys
- `StreamingAgent::isLFE(sourceName)` — LFE detection for routing in Phase 5
- The audio callback in `processBlock()` is the insertion point for Pose Agent (Phase 3) and Spatializer Agent (Phase 4)
- Current mono mix (equal-sum to all channels) will be replaced by per-source DBAP panning in Phase 4

### Phase 3 Completion Log (Pose — Source Position Interpolation)

**Files created/modified:**

| File                                                    | Action       | Purpose                                                                                                                                                                                                                                                            |
| ------------------------------------------------------- | ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `spatial_engine/realtimeEngine/src/Pose.hpp`            | **Created**  | Agent 2 — source position interpolation and layout-aware transforms. SLERP between LUSID keyframes, elevation sanitization (3 modes), DBAP coordinate transform. Outputs `SourcePose` vector per audio block.                                                      |
| `spatial_engine/realtimeEngine/src/RealtimeTypes.hpp`   | **Modified** | Added `ElevationMode` enum (Clamp, RescaleAtmosUp, RescaleFullSphere) and `elevationMode` field to `RealtimeConfig`.                                                                                                                                               |
| `spatial_engine/realtimeEngine/src/RealtimeBackend.hpp` | **Modified** | Added `Pose*` pointer and `setPose()` method. `processBlock()` now calls `mPose->computePositions(blockCenterSec)` at step 1.5, computing per-source positions before the audio mixing loop. Positions are computed but not yet used for spatialization (Phase 4). |
| `spatial_engine/realtimeEngine/src/main.cpp`            | **Modified** | Now loads speaker layout via `LayoutLoader::loadLayout()`, creates `Pose`, calls `pose.loadScene(scene, layout)` to analyze layout and store keyframes, wires Pose into backend via `backend.setPose(&pose)`. Updated to Phase 3 banner and help text.             |
| `internalDocsMD/AGENTS.md`                              | **Modified** | Updated Phase 3 row to ✅ Complete, added `Pose.hpp` description to Key Files section.                                                                                                                                                                             |

**Design decisions:**

- **SLERP interpolation** (not linear Cartesian): Prevents direction vectors from passing through near-zero magnitude when keyframes are far apart on the sphere. Adapted from `SpatialRenderer::slerpDir()`.
- **Three elevation modes**: `Clamp` (hard clip to layout bounds), `RescaleAtmosUp` (default, maps [0,π/2] → layout), `RescaleFullSphere` (maps [-π/2,π/2] → layout). Identical to offline renderer.
- **DBAP coordinate transform**: Our system (y-forward, x-right, z-up) → AlloLib DBAP internal does `Vec3d(pos.x, -pos.z, pos.y)`, so we pre-compensate with `(x, z, -y)`. Adapted from `SpatialRenderer::directionToDBAPPosition()`.
- **Layout radius = median speaker distance**: Same calculation as offline renderer constructor. Used to scale unit direction vectors to DBAP positions at the speaker ring distance.
- **2D detection**: If speaker elevation span < 3°, all directions are flattened to the horizontal plane (z=0). Same threshold as offline renderer.
- **Fallback chain for degenerate directions**: (1) normalize raw interpolation, (2) last-good cached direction, (3) nearest keyframe direction, (4) front (0,1,0). Same logic as `SpatialRenderer::safeDirForSource()`.
- **Block-center sampling**: Position is computed at the center of each audio block (`frameCounter + bufferSize/2`) per design doc specification.
- **Pre-allocated output vector**: `mPoses` and `mSourceOrder` are allocated once at `loadScene()` time. `computePositions()` updates entries in-place — no allocation on the audio thread.
- **`std::map` for keyframe lookup**: Acceptable because `computePositions()` iterates sequentially through the pre-built source order, not doing random lookups. The map is read-only during playback.

**Build & test results:**

- `cmake --build .` compiles with zero errors
- 35 sources loaded, 54 speakers + 1 subwoofer in AlloSphere layout
- Layout analysis: median radius 5.856m, elevation [-27.7°, 32.7°], 3D mode
- Ran for 8.6 seconds with 2 output channels, --gain 0.3
- CPU load: 0.0% (SLERP + transforms for 35 sources add negligible overhead)
- No xruns, no crashes
- Clean shutdown via SIGINT

**What the next phase gets:**

- `Pose::computePositions(blockCenterTimeSec)` — called once per audio block, updates internal pose vector
- `Pose::getPoses()` → `const vector<SourcePose>&` — per-source `{name, position, isLFE, isValid}` ready for DBAP
- Positions are in DBAP-ready coordinates (pre-transformed), scaled to layout radius
- LFE sources have `isLFE=true` → route to subwoofer channels, skip DBAP
- The spatializer (Phase 4) will iterate `getPoses()` and compute per-speaker gain coefficients

### Phase 4 Completion Log (Spatializer — DBAP Spatial Panning)

**Files created/modified:**

| File                                                    | Action       | Purpose                                                                                                                                                                                                                                                                          |
| ------------------------------------------------------- | ------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `spatial_engine/realtimeEngine/src/Spatializer.hpp`     | **Created**  | Agent 3 — DBAP spatial audio panning. Builds `al::Speakers` from layout, computes output channels from layout, creates `al::Dbap`, renders all sources via internal render buffer, routes LFE to subwoofers. Internal render buffer is the future Channel Remap insertion point. |
| `spatial_engine/realtimeEngine/src/RealtimeTypes.hpp`   | **Modified** | `outputChannels` default changed from 60 → 0. Now computed from speaker layout by `Spatializer::init()`. Added documentation comment explaining the formula.                                                                                                                     |
| `spatial_engine/realtimeEngine/src/RealtimeBackend.hpp` | **Modified** | Added `Spatializer*` pointer and `setSpatializer()` method. `processBlock()` now calls Spatializer `renderBlock()` instead of the Phase 2 mono-mix fallback. Pipeline: zero outputs → Pose positions → Spatializer render → update state → CPU monitor.                          |
| `spatial_engine/realtimeEngine/src/main.cpp`            | **Modified** | Removed `--channels` CLI argument. Creates `Spatializer`, calls `init(layout)` which computes `outputChannels` into config. Backend reads the layout-derived channel count. Updated help text, banner, and config printout.                                                      |
| `internalDocsMD/AGENTS.md`                              | **Modified** | Updated Phase 4 row to ✅ Complete, added `Spatializer.hpp` description, updated run example (no `--channels`), updated file tree.                                                                                                                                               |

**Design decisions:**

- **Layout-derived output channels** (not user-specified): `outputChannels = max(numSpeakers-1, max(subwooferDeviceChannels)) + 1`. Same formula as offline `SpatialRenderer.cpp` (lines 837-842). For the Allosphere layout: `max(53, 55) + 1 = 56`. Removed the `--channels` CLI flag entirely.
- **Internal render buffer (`mRenderIO`)**: All rendering (DBAP + LFE) goes into an `al::AudioIOData` buffer sized to `outputChannels`. The copy step from render buffer → real AudioIO is the future **Channel Remap insertion point**, where logical render channels will be mapped to physical device outputs (like `channelMapping.hpp`'s `defaultChannelMap` does for the Allosphere ADM player). Currently identity mapping.
- **Nothing hardcoded to any layout**: No Allosphere-specific values anywhere. Channel count, speaker positions, subwoofer channels — all derived from the layout JSON at runtime. Works with any speaker layout.
- **Consecutive 0-based speaker channels**: Same as offline renderer. `al::Speaker` gets indices 0..N-1 for N speakers. The hardware `deviceChannel` numbers from the layout JSON (1-based, non-consecutive with gaps) are only used for subwoofer routing. Future Channel Remap will handle mapping render channels to hardware channels.
- **LFE into render buffer** (not directly to AudioIO): LFE sources write into `mRenderIO` subwoofer channels, so all audio flows through the same remap point. Consistent with the design where the copy step is the single point of channel routing.
- **Sub compensation**: `masterGain * 0.95 / numSubwoofers` — same formula as offline `SpatialRenderer::renderPerBlock()`.
- **DBAP panning**: Uses `al::Dbap::renderBuffer()` directly. Source audio is pre-multiplied by `masterGain` before DBAP accumulates into speaker channels. Focus parameter is configurable via `RealtimeConfig::dbapFocus`.

**Build & test results:**

- `cmake .. && make -j4` compiles with zero errors
- 35 sources loaded, 54 speakers + 1 subwoofer in AlloSphere layout
- Output channels derived from layout: 56 (speakers 0-53, sub at deviceChannel 55)
- AudioIO opened with 56 output channels
- Internal render buffer: 56 channels × 512 frames
- Ran for 6 seconds with `--gain 0.1`
- CPU load: 0.0% (DBAP for 35 sources × 54 speakers + LFE is trivially fast)
- No xruns, no assertion failures, no crashes
- Clean shutdown via SIGINT/kill

**What the next phase gets:**

- `Spatializer::renderBlock(io, streaming, poses, frame, numFrames)` — renders all sources into the real AudioIO output
- Layout-derived `config.outputChannels` — backend opens AudioIO with the right channel count automatically
- Internal render buffer (`mRenderIO`) — future Channel Remap agent replaces the identity copy loop with a mapping table
- LFE routing already handled (subwoofer channels from layout, no DBAP on LFE sources)
- Phases 1-4 together form the **minimum audible spatial prototype** — sound comes out of the correct speakers based on LUSID scene positions

### ADM Direct Streaming Completion Log (Optimization — Skip Stem Splitting)

**Files created/modified:**

| File                                                       | Action       | Purpose                                                                                                                                                                                                                                                                                                   |
| ---------------------------------------------------------- | ------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `spatial_engine/realtimeEngine/src/MultichannelReader.hpp` | **Created**  | Shared multichannel WAV reader. Opens one SNDFILE\*, pre-allocates interleaved buffer (chunkFrames × numChannels), de-interleaves channels into per-source SourceStream double buffers. Method implementations in Streaming.hpp (after SourceStream definition).                                          |
| `spatial_engine/realtimeEngine/src/Streaming.hpp`          | **Modified** | Added `loadSceneFromADM()` (creates buffer-only SourceStreams, maps to MultichannelReader), `loaderWorkerMultichannel()` (one bulk read fills all mapped streams), `SourceStream::initBuffersOnly()` (allocates buffers without file handle), `parseChannelIndex()` (source key → 0-based channel index). |
| `spatial_engine/realtimeEngine/src/RealtimeTypes.hpp`      | **Modified** | Added `std::string admFile` to `RealtimeConfig` for ADM direct streaming path.                                                                                                                                                                                                                            |
| `spatial_engine/realtimeEngine/src/main.cpp`               | **Modified** | Added `--adm <path>` CLI flag (mutually exclusive with `--sources`). Dispatches to `loadSceneFromADM()` or `loadScene()`. Updated help text.                                                                                                                                                              |
| `src/packageADM/packageForRender.py`                       | **Modified** | Added `writeSceneOnly()` function — writes scene.lusid.json without splitting stems.                                                                                                                                                                                                                      |
| `runRealtime.py`                                           | **Modified** | `_launch_realtime_engine()` now accepts `adm_file` parameter (uses `--adm` flag). `run_realtime_from_ADM()` calls `writeSceneOnly()` instead of `packageForRender()`, skipping stem splitting entirely.                                                                                                   |
| `internalDocsMD/AGENTS.md`                                 | **Modified** | Updated all realtime engine descriptions for dual-mode streaming, added MultichannelReader.hpp docs, updated run examples.                                                                                                                                                                                |

**Design decisions:**

- **Shared MultichannelReader (Option A)**: One SNDFILE\*, one interleaved buffer (~44MB for 48ch), shared across all sources. Much more memory-efficient than per-source multichannel handles (Option B, rejected).
- **Channel mapping derived in C++**: Source key `"11.1"` → extract number before dot → subtract 1 → channel index 10. `"LFE"` → hardcoded index 3 (standard ADM LFE position). No LUSID schema changes needed.
- **Audio thread completely untouched**: SourceStream's double-buffer + getSample/getBlock are identical in both modes. The audio callback doesn't know or care whether data came from mono files or de-interleaved multichannel.
- **Mono path preserved**: `--sources` still works exactly as before (zero regression risk).
- **Separate loader workers**: `loaderWorkerMono()` (original per-source iteration) and `loaderWorkerMultichannel()` (one bulk read per cycle) avoid any conditional branching in the hot loop.
- **`writeSceneOnly()`**: Factored out of `packageForRender()` to write just the scene.lusid.json without stem splitting. Used by the real-time ADM path; offline pipeline still uses full `packageForRender()`.

**Build & test results:**

- `cmake .. && make -j4` compiles with zero errors
- `--help` shows new `--adm` flag and updated usage
- Error handling: `--adm` + `--sources` together rejected; neither provided rejected
- LUSID package path (mono): ✅ No regression — 78 sources, allosphere layout, 56 output channels
- ADM WAV path (direct streaming): ✅ Full pipeline works — SWALE-ATMOS-LFE.wav, 24 sources mapped from 48ch ADM, translab layout, 18 output channels
- ADM pipeline skips Step 4 (stem splitting) — saves ~30-60 seconds and ~2.9GB disk I/O

### Phase 5 Skip Log (LFE Router — Skipped)

**Decision:** Phase 5 (LFE Router) is **skipped** for the v1 prototype.

**Rationale:** LFE routing is already fully implemented inside `Spatializer.hpp`
(Phase 4). LFE sources are identified by `pose.isLFE`, bypass DBAP entirely,
and route directly to subwoofer channels from the speaker layout with
`subGain = masterGain * 0.95 / numSubwoofers` — the same formula as the offline
renderer. This pass-through approach matches the offline pipeline's behavior
and is sufficient for the current prototype.

The `agent_lfe_router.md` design document describes bass management features
(crossover filtering, extracting LF content from main speakers, phase alignment)
that are **not needed** for replicating the offline pipeline in real-time. These
are deferred to the "Possible Future Development" section below as lowest
priority / experimental.

**What the next phase gets (unchanged from Phase 4):**

- LFE sources routed to subwoofer channels (already implemented in Spatializer)
- No new files created or modified
- No behavioral changes

---

### Phase 6 Completion Log (Compensation and Gain)

**Files modified:**

| File                                                | Action       | Purpose                                                                                                                                                                                                                                                                                                                                                                                                     |
| --------------------------------------------------- | ------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `spatial_engine/realtimeEngine/src/Spatializer.hpp` | **Modified** | Added `isSubwooferChannel()` private helper. Added Phase 6 mix-trim pass in `renderBlock()` — applies `loudspeakerMix` to all non-sub channels and `subMix` to sub channels in `mRenderIO` after DBAP+LFE, before copy-to-output. Added `computeFocusCompensation()` public method. Added `mLayoutRadius` member, populated at `init()` time using the median speaker radius. Added `#include <algorithm>`. |
| `spatial_engine/realtimeEngine/src/main.cpp`        | **Modified** | Updated banner to Phase 6. After Spatializer init, calls `computeFocusCompensation()` if `--auto_compensation` is active. Prints Phase 6 gain summary (loudspeakerMix, subMix in dB). Updated help text and comment block.                                                                                                                                                                                  |

**Design decisions:**

- **Mix trims applied to `mRenderIO`** — after all DBAP and LFE rendering, before the copy-to-output step. This is the precise location specified in the design doc and means `masterGain` (already baked into DBAP gains per source) and the post-DBAP trims are independent, non-interfering scalars.
- **Unity guard (`!= 1.0f`)** — the trim loops are entirely skipped at the default 0 dB setting. Zero additional cost for the common case.
- **`isSubwooferChannel()` helper** — a linear scan over `mSubwooferChannels` (typically 1-2 entries). Called O(renderChannels) times per block only when `spkMix != 1.0f`, which is negligible.
- **`computeFocusCompensation()` runs on the main/control thread only** — it allocates temporary `al::AudioIOData` and `al::Dbap` objects for an offline impulse test, computes the RMS power ratio between focus=current and focus=0, then writes the square-root amplitude scalar to `mConfig.loudspeakerMix`. It must not be called from the audio callback.
- **Reference position = (0, mLayoutRadius, 0)** — front-center at the layout radius, in DBAP-ready coordinates. Consistent with how Pose transforms directions before handing to DBAP.
- **Compensation clamped to ±10 dB** (0.316–3.162 linear) — matches the design doc range and guards against division-by-near-zero at extreme focus values.
- **`RealtimeConfig` already had the three atomics** (`loudspeakerMix`, `subMix`, `focusAutoCompensation`) and `main.cpp` already parsed the CLI flags from a previous forward-looking commit. Phase 6 completes the implementation by wiring them into the audio path.

**Build & test results:**

- `cmake --build . -j4` compiles with zero errors
- `--speaker_mix 6` → `loudspeakerMix=1.995` (≈+6 dB), sub unchanged
- `--sub_mix -6` → `subMix=0.501` (≈-6 dB), mains unchanged
- Both sliders at 0 dB → unity guard fires, no extra computation
- `--auto_compensation` → `computeFocusCompensation()` called at startup, logs loudspeakerMix in dB

**What the next phase gets:**

- `mConfig.loudspeakerMix` and `mConfig.subMix` are live atomics — any agent (GUI, control thread) can update them at runtime and the audio callback picks them up within one block
- `spatializer.computeFocusCompensation()` is callable from any non-audio-thread context when focus changes
- The copy-from-render-to-output section in `renderBlock()` is now cleanly separated from the gain application section, making it the clear insertion point for the Channel Remap agent (Phase 7)

---

### Phase 7 Completion Log (Output Remap)

**Files created/modified:**

| File                                                | Action       | Purpose                                                                                                                                                                                                                                                                                          |
| --------------------------------------------------- | ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `spatial_engine/realtimeEngine/src/OutputRemap.hpp` | **Created**  | CSV-based channel remap table. Parses a `layout,device` CSV once at startup. Stores a compact `std::vector<RemapEntry>` for the audio thread to iterate. Detects identity maps and sets the `identity=true` fast-path flag. All out-of-range rows are dropped and logged once (never per-frame). |
| `spatial_engine/realtimeEngine/src/Spatializer.hpp` | **Modified** | Added `#include "OutputRemap.hpp"`. Added `mRemap` (const pointer, default nullptr). Added `setRemap()` method. Replaced the old identity-copy loop in `renderBlock()` with a two-branch remap: identity fast-path (bit-identical to Phase 6) or accumulate-via-entries-list remap path.         |
| `spatial_engine/realtimeEngine/src/main.cpp`        | **Modified** | Added `#include "OutputRemap.hpp"`. Added `--remap <path>` CLI flag + help text. After Spatializer init, creates an `OutputRemap`, calls `load()` with render and device channel counts, passes `&outputRemap` to `spatializer.setRemap()`. Updated banner to Phase 7 and comment block.         |

**Design decisions:**

- **CSV schema from the spec**: `layout,device` headers required (case-insensitive), 0-based indices, extra columns ignored, `#` comment lines and empty lines skipped. Matches `agent_output_remap.md` exactly.
- **Accumulate (not replace)**: multiple `layout` entries mapping to the same `device` channel are summed, matching the AlloApp reference behavior in `channelMapping.hpp`.
- **Identity detection**: after parsing, `checkIdentity()` verifies that every entry has `layout == device`, there are no duplicates, and coverage is complete (exactly `renderChannels` entries). Only then is the fast-path flag set.
- **No ownership transfer**: `OutputRemap` is stack-allocated in `main()` and passed as a `const*`. The Spatializer never deletes it. The object lives for the entire playback duration.
- **No `--remap` → zero overhead**: when the flag is omitted, `setRemap()` is never called (`mRemap` stays `nullptr`), the `identity` branch fires, and the loop is identical to pre-Phase-7 code.
- **Device channel count for range-checking**: `load()` is called with `config.outputChannels` for both `renderChannels` and `deviceChannels`. Since the engine currently uses identity hardware mapping, both counts are the same layout-derived value. Phase 8 or the Allosphere-specific CSV will use the real device channel count.
- **Allosphere usage**: to apply the Allosphere-specific remap, generate a CSV from `channelMapping.hpp`'s `defaultChannelMap` (54 entries + sub) and pass it with `--remap allosphere.csv`. No code change needed.

**Build & test results:**

- `cmake --build . -j4` compiles with zero errors
- No `--remap` → identity fast-path, output bit-identical to Phase 6
- `--remap identity.csv` (all `layout==device`) → identity detected, fast-path active
- `--remap swap.csv` (two channels swapped) → remap path active, entries logged

**What the next phase gets:**

- `Spatializer::setRemap(const OutputRemap*)` — can be called at any time before audio starts
- `OutputRemap::load(path, renderCh, deviceCh)` — returns true on success, logs warnings on bad rows
- The audio output is now fully configurable for any hardware channel layout via a two-column CSV
- Phase 8 (Threading and Safety) can harden the existing atomic usage; no new remap-related thread concerns (the table is immutable during playback)

---

## Possible Future Development

> Items below are not planned for the v1 prototype. They are listed in
> priority order for future consideration.

### X. Audio driver and OS compatibility

Add a tiny “device sanity toolkit” (non-RT):

Print: device name, host API, output channel count

“Channel ID” test mode (pulse each layout channel)

explore potential issues with ASIO (and WASAPI/DirectSound)

### 1. Single-Keyframe Pose Optimization (Medium Priority)

**Analysis:** `Pose::computePositions()` unconditionally recomputes the full
SLERP → sanitize → coordinate-transform pipeline for every non-LFE source on
every audio block, even when the source's position hasn't changed. This
includes sources with:

- **A single keyframe** (e.g., DirectSpeaker bed channels, which are inherently
  static). These go through `interpolateDirRaw()` → `safeDirForSource()` →
  `sanitizeDirForLayout()` → `directionToDBAPPosition()` every block despite
  always returning the same position.
- **Multiple keyframes but currently in a hold segment** (before the first
  keyframe or after the last, where the result is clamped and constant).

**Current impact:** Negligible — Phase 3 testing showed 0.0% CPU for 35 sources.
The SLERP + trig is a handful of floating-point ops per source per block.

**Optimization (when needed):**

1. **Static source fast path:** At `loadScene()` time, detect sources with
   exactly 1 keyframe (or all keyframes at the same position). Pre-compute
   their DBAP-ready position once and store it directly in `mPoses[i]`.
   In `computePositions()`, skip these sources entirely.
2. **Time-segment caching:** Cache which keyframe segment (k1, k2) was used
   on the previous block. If the new block-center time is still in the same
   segment and the interpolation parameter `u` hasn't changed significantly
   (within epsilon), skip recomputation.

**Estimated benefit:** For typical ADM content (many static bed channels +
fewer moving objects), this could skip 50-80% of sources. Worth implementing
when source counts reach hundreds or when CPU headroom becomes tight.

### 2. Bass Management / LFE Crossover Filtering (Lowest Priority — Experimental)

**Description:** The `agent_lfe_router.md` document describes a full bass
management system with:

- Low-pass filtering (e.g., 80 Hz Butterworth) to extract LF content from main
  speaker channels and redirect to subwoofers
- Optional complementary high-pass on main channels to avoid LF doubling
- Phase-aligned crossover (Linkwitz-Riley option)
- Per-channel biquad filter states, pre-allocated for RT safety
- Configurable crossover frequency, additive vs. redirected bass modes

**Why deferred:** The current pass-through LFE routing (dedicated LFE sources →
subwoofer channels, no crossover) matches the offline pipeline exactly. Bass
management is a separate concern from spatial rendering — it's a playback
system feature that depends on the physical speaker setup (whether mains are
full-range or satellite + sub). Adding it would introduce complexity and
configuration surface area that isn't needed for the v1 goal of "replicate
the offline pipeline in real-time."

**If implemented later:** Create a new `LFERouter.hpp` agent that runs after
the Spatializer's render pass but before the copy-to-output step. It would
operate on the internal render buffer (`mRenderIO`) channels. The Spatializer's
existing LFE pass-through routing should remain as-is (it handles dedicated LFE
source content); bass management would be additive, extracting LF from the
main speaker channels.

---

## Critical Implementation Details for Future Context Windows

> These details were captured at the end of the ADM Direct Streaming implementation
> session to preserve context that isn't obvious from reading code alone.

### Full LFE Channel Mapping Chain (Python → C++)

The LFE channel mapping crosses two codebases and involves a hardcoded flag:

1. **Python LUSID parser** (`LUSID/src/xml_etree_parser.py` line 44):
   `_DEV_LFE_HARDCODED = True` — when `True`, any DirectSpeaker at 1-based
   ADM channel 4 is tagged as LFE (function `_is_lfe_channel()`). When `False`,
   it falls back to checking `speakerLabel` for the substring "lfe".

2. **LUSID scene JSON output**: The LFE source gets key `"LFE"` (from the
   `LFENode(id=f"{group_id}.1")` construction at line 371). In the SWALE test
   file, the DirectSpeaker group containing channel 4 has `group_id = "4"`,
   so the LFE source key becomes `"4.1"` in the scene — but its **type** is
   `"lfe"` in the JSON, so the C++ engine identifies it as LFE.

3. **C++ `parseChannelIndex()`** (`Streaming.hpp`): For source key `"LFE"` or
   any source flagged as LFE, returns hardcoded index 3 (0-based ADM channel 4).
   For normal sources like `"11.1"`, extracts the number before the dot and
   subtracts 1 → channel index 10.

4. **C++ `Spatializer.hpp`**: LFE sources (identified by `pose.isLFE`) bypass
   DBAP entirely and route directly to subwoofer channels from the speaker layout.

**Implication**: Changing `_DEV_LFE_HARDCODED` to `False` in the parser will
make LFE detection label-based, but the C++ `parseChannelIndex()` hardcoded
index 3 would still need to be made dynamic (read from the scene JSON).

### Shared Loaders — Offline ↔ Real-Time Code Sharing

The real-time engine compiles three `.cpp` files from the offline renderer's
`spatial_engine/src/` directory (see `realtimeEngine/CMakeLists.txt` lines 29-33):

```
add_executable(sonoPleth_realtime
    src/main.cpp
    ../src/JSONLoader.cpp      # Parses scene.lusid.json → SpatialData struct
    ../src/LayoutLoader.cpp    # Parses speaker_layout.json → SpeakerLayout struct
    ../src/WavUtils.cpp        # WAV I/O (used for metadata only in realtime)
)
```

These are the **exact same source files** the offline renderer
(`spatial_engine/spatialRender/`) uses. Any changes to these shared files affect
both the offline and real-time pipelines. The offline renderer is at
`spatial_engine/spatialRender/build/sonoPleth_spatial_render`.

### Circular Header Pattern (MultichannelReader ↔ Streaming)

`MultichannelReader.hpp` forward-declares `struct SourceStream` and declares
methods `deinterleaveInto(SourceStream&, ...)` and `zeroFillBuffer(SourceStream&, ...)`.
The **implementations** of these methods are placed at the very bottom of
`Streaming.hpp` (after `SourceStream` is fully defined) as inline free-standing
functions within the `MultichannelReader` class scope. This is standard C++ for
resolving circular dependencies between header-only types. If you move
`SourceStream` to its own header, the method impls should move with it.

### Known Bug — `runPipeline.py` Line 177

In the `if __name__ == "__main__"` CLI block, the LUSID branch calls:

```python
run_pipeline_from_LUSID(sourceADMFile, sourceSpeakerLayout, renderMode, createRenderAnalysis, outputRenderPath)
```

But `outputRenderPath` is **never defined** in this code path (it's only a
default parameter in `run_pipeline_from_ADM()`). This will crash with
`NameError` if someone runs the offline pipeline CLI with a LUSID package input.
**Not a real-time engine issue** — but worth knowing about.

### Audio Scan Toggle — `scan_audio` (✅ Implemented)

The ADM real-time path (`run_realtime_from_ADM()`) previously ran a full
per-channel audio activity scan unconditionally at Step 2, adding ~14 seconds
of startup latency before the engine could launch.

**What changed (`runRealtime.py`):**

| Step | What it does                               | Default     |
| ---- | ------------------------------------------ | ----------- |
| 2a   | `exportAudioActivity()` — write JSON       | **skipped** |
| 2b   | `channelHasAudio()` — scan full WAV        | **skipped** |
| 2c   | Synthetic all-active dict passed to parser | **used**    |

- `run_realtime_from_ADM()` gains a `scan_audio=False` keyword argument.
- When `False` (the default): both scan calls are skipped. A synthetic
  `contains_audio_data` dict is built from `sf.info()` alone (no I/O beyond
  the file header), marking all channels active. Startup time drops by ~14s.
- When `True`: the original scan runs and writes `processedData/containsAudio.json`
  as before. Use this if the LUSID parser needs accurate silence data.
- CLI flag: append `--scan_audio` to the positional arguments to enable it.
  Absence of the flag means `False`.
- The LUSID path (`run_realtime_from_LUSID`) has no scan — unaffected.

**Synthetic fallback dict format** (matches `channelHasAudio()` return schema):

```python
{
    "sample_rate": <int>,
    "threshold_db": -100,
    "elapsed_seconds": 0.0,
    "channels": [
        {"channel_index": i, "rms_db": 0.0, "contains_audio": True}
        for i in range(num_channels)
    ]
}
```

---

### Phase 8 Completion Log — Threading and Safety (✅ Complete)

**Approach:** Full threading audit of all five agents. The engine was already
largely correct. Phase 8 replaced ambiguous comments with precise threading
contracts, added a hardened null-pointer guard, and produced the canonical
threading model documentation that future phases (GUI) must respect.

**No new runtime mechanisms were needed.** All synchronization was already in
place (atomics with correct memory orders, happens-before from `start()`,
double-buffer acquire/release pairs). Phase 8's contribution is the explicit,
auditable specification of what each thread owns and what the rules are.

#### Threading Model Reference Table

| Thread     | Owns (exclusive write)                                                                            | Read-only access                                                         | Sync mechanism                                               |
| ---------- | ------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------ | ------------------------------------------------------------ |
| **MAIN**   | Agent lifetimes; `mLoaderRunning` (→ false); startup setup                                        | `EngineState` atomics (for display)                                      | `memory_order_relaxed` on reads                              |
| **AUDIO**  | `mPoses`, `mLastGoodDir` (Pose); `mRenderIO`, `mSourceBuffer` (Spatializer); `EngineState` writes | `mConfig` atomics; `mStreams` (read-only); agent pointers                | `memory_order_relaxed` (sole writer for EngineState)         |
| **LOADER** | Inactive buffer slot of `SourceStream::bufferA/B`                                                 | `EngineState::frameCounter` (relaxed); `stateA/B` (acquire) to pick slot | acquire/release on `stateA/B`, `chunkStart*`, `validFrames*` |

#### Invariants Documented (now in RealtimeTypes.hpp)

1. Agent pointers in `RealtimeBackend` set **once** before `start()`, **never** changed during playback — no sync needed (happens-before from `start()`).
2. All agent data structures fully populated before `start()`, read-only during playback (audio thread reads only).
3. `Streaming::shutdown()` **must** be called only **after** `Backend::stop()` returns — see shutdown ordering contract in `Streaming.hpp`.
4. `Pose::computePositions()` is **audio-thread-only** — `mPoses` and `mLastGoodDir` are exclusively owned by the audio thread.
5. `Spatializer::computeFocusCompensation()` is **main-thread-only, not RT-safe** — must not be called while audio is streaming.
6. Loader thread only writes to EMPTY buffers; audio thread only reads PLAYING buffers — the `LOADING → READY` state transition with `memory_order_release` ensures data visibility before the state flip.

#### Memory Order Audit Results

| Atomic                                                      | Order used                       | Verdict                                                                    |
| ----------------------------------------------------------- | -------------------------------- | -------------------------------------------------------------------------- |
| `RealtimeConfig::masterGain` / `loudspeakerMix` / `subMix`  | relaxed (both r/w)               | ✅ Correct — gain staleness of one buffer is inaudible and not a data race |
| `RealtimeConfig::playing` / `shouldExit`                    | relaxed                          | ✅ Correct — polling only, no dependent memory                             |
| `EngineState::frameCounter` / `playbackTimeSec` / `cpuLoad` | relaxed                          | ✅ Correct — single writer (audio); display lag of one buffer is fine      |
| `SourceStream::stateA/B`                                    | release (write) / acquire (read) | ✅ Correct — synchronizes buffer data visibility                           |
| `SourceStream::chunkStartA/B` / `validFramesA/B`            | release / acquire                | ✅ Correct — same acquire/release pair                                     |
| `SourceStream::activeBuffer`                                | release / acquire                | ✅ Correct — buffer switch is visible atomically                           |
| `Streaming::mLoaderRunning`                                 | release (false) / acquire (poll) | ✅ Correct — loader sees the stop signal                                   |

#### Files Modified

| File                                                    | Change summary                                                                                                                                                                                                                                                                                                             |
| ------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `spatial_engine/realtimeEngine/src/RealtimeTypes.hpp`   | Added 60-line threading model doc block (thread table, memory order table, 6 invariants). Updated gain-atomics comment to remove stale "Phase 6 adds" note.                                                                                                                                                                |
| `spatial_engine/realtimeEngine/src/RealtimeBackend.hpp` | Updated `processBlock()` comment to reflect all phases done (removed "Future phases" stubs). Added threading annotations to agent pointer and cached-data member sections. Added `memory_order_relaxed` justification comment on EngineState writes.                                                                       |
| `spatial_engine/realtimeEngine/src/Streaming.hpp`       | Added 50-line threading model block to file header (three-thread table, memory ordering protocol, **shutdown ordering contract**). Rewrote `shutdown()` comment to explicitly state the caller precondition and explain why `mStreams.clear()` is safe.                                                                    |
| `spatial_engine/realtimeEngine/src/Pose.hpp`            | Added threading model block (main/audio/loader roles, read-only vs. audio-thread-owned data, note on `mLastGoodDir` first-block allocation). Updated `computePositions()` doc to add `THREADING: AUDIO THREAD ONLY` warning.                                                                                               |
| `spatial_engine/realtimeEngine/src/Spatializer.hpp`     | Added threading model block (main/audio/loader roles, read-only vs. audio-thread-owned data). Updated `computeFocusCompensation()` header to replace vague "control/main thread" with explicit `THREADING: MAIN THREAD ONLY` + reason + correct usage guide. Updated member data comments with per-field thread ownership. |

**Build result:** `cmake --build . -j4` — zero errors, zero warnings (all changes are comments and doc strings only; no compiled code changed).

---

### Exact File Paths for Key Artifacts

| Artifact                          | Path                                                                                        |
| --------------------------------- | ------------------------------------------------------------------------------------------- |
| Real-time C++ executable          | `spatial_engine/realtimeEngine/build/sonoPleth_realtime`                                    |
| Offline C++ executable            | `spatial_engine/spatialRender/build/sonoPleth_spatial_render`                               |
| CMakeLists (real-time)            | `spatial_engine/realtimeEngine/CMakeLists.txt`                                              |
| Shared JSONLoader                 | `spatial_engine/src/JSONLoader.cpp` / `.hpp`                                                |
| Shared LayoutLoader               | `spatial_engine/src/LayoutLoader.cpp` / `.hpp`                                              |
| Shared WavUtils                   | `spatial_engine/src/WavUtils.cpp` / `.hpp`                                                  |
| LUSID XML parser                  | `LUSID/src/xml_etree_parser.py`                                                             |
| LUSID scene model                 | `LUSID/src/scene.py`                                                                        |
| Package/scene writer              | `src/packageADM/packageForRender.py` (has both `packageForRender()` and `writeSceneOnly()`) |
| Python launcher                   | `runRealtime.py` (project root)                                                             |
| Speaker layouts dir               | `spatial_engine/speaker_layouts/`                                                           |
| Processed data (scene JSON, etc.) | `processedData/stageForRender/scene.lusid.json`                                             |
| ADM extracted metadata            | `processedData/currentMetaData.xml`                                                         |
| LUSID schema                      | `LUSID/schema/lusid_scene_v0.5.schema.json`                                                 |
| Design doc (streaming/DBAP)       | `internalDocsMD/realtime_planning/realtimeEngine_designDoc.md`                              |
| ADM streaming design doc          | `internalDocsMD/realtime_planning/agentDocs/agent_adm_direct_streaming.md`                  |

### Verified Test Commands (End-to-End)

```bash
# ADM direct streaming (SWALE test file, TransLab layout):
python runRealtime.py sourceData/SWALE-ATMOS-LFE.wav \
    spatial_engine/speaker_layouts/translab-sono-layout.json

# LUSID package (pre-split mono stems, Allosphere layout):
python runRealtime.py sourceData/lusid_package \
    spatial_engine/speaker_layouts/allosphere_layout.json 0.3 1.5 512

# C++ engine directly (ADM mode):
cd spatial_engine/realtimeEngine
./build/sonoPleth_realtime \
    --layout ../speaker_layouts/translab-sono-layout.json \
    --scene ../../processedData/stageForRender/scene.lusid.json \
    --adm ../../sourceData/SWALE-ATMOS-LFE.wav \
    --gain 0.5 --buffersize 512

# C++ engine directly (mono mode):
./build/sonoPleth_realtime \
    --layout ../speaker_layouts/allosphere_layout.json \
    --scene ../../processedData/stageForRender/scene.lusid.json \
    --sources ../../sourceData/lusid_package \
    --gain 0.1 --buffersize 512

# Build from scratch:
cd spatial_engine/realtimeEngine/build
cmake ..
make -j4
```

### Python Environment

- **Venv**: `sonoPleth/bin/python` (Python 3.12.2)
- **Activation**: `source activate.sh` (from project root)
- **Key packages**: PySide6 (GUI), lxml (legacy XML), gdown (example downloads)

---

## Architecture Overview

This real-time spatial audio engine is designed as a collection of specialized **agents**, each handling a distinct aspect of audio processing. Splitting functionality into separate agents enables **sequential, testable development** where each piece is verified before the next begins. The engine's goal is to render spatial audio with minimal latency and no glitches, even under heavy load, by carefully coordinating these components.

Key design goals include:

- **Hard Real-Time Performance:** The audio processing must complete within each audio callback frame (e.g. on a 512-sample buffer at 48 kHz, ~10.7ms per callback) to avoid underruns or glitches. Each agent is designed to do its work within strict time budgets:contentReference[oaicite:0]{index=0}.
- **Modularity:** Each agent has a clear responsibility and interface, making the system easier to maintain and allowing multiple team members to work in parallel.
- **Thread Safety:** Agents communicate via thread-safe or lock-free structures to avoid blocking the high-priority audio thread. No dynamic memory allocation or unbounded waits occur in the audio callback.
- **Scalability:** The architecture should handle multiple audio sources and outputs, scaling with available CPU cores by distributing work across threads where possible.

## Agents and Responsibilities

Below is a summary of each agent in the system and its primary responsibilities:

- **Streaming Agent:** Handles input audio streams (file, network, or live sources). It reads, decodes, and buffers audio data for each source, providing timely audio buffers to the engine.
- **Pose and Control Agent:** Manages dynamic source and listener states (positions, orientations, and control commands). It processes external controls (e.g., from GUI or network) and updates the shared scene data (source positions, activation, etc.).
- **Spatializer (DBAP) Agent:** Core audio processing module that spatializes audio using Distance-Based Amplitude Panning (DBAP). It computes gain coefficients for each source-to-speaker path and mixes source audio into the appropriate output channels based on spatial positions.
- **LFE Router Agent:** Extracts and routes low-frequency content to the Low-Frequency Effects (LFE) channel. It ensures subwoofer output is properly generated (e.g., by low-pass filtering content or routing dedicated LFE sources) without affecting main channel clarity.
- **Output Remap Agent:** Maps and adapts the engine’s output channel layout to the actual audio output hardware or desired format. This includes reordering or downmixing channels to match the device configuration (e.g., mapping internal channels to sound card output channels).
- **Compensation and Gain Agent:** Solves the focus/sub balance problem. As DBAP `focus` increases, main speaker power drops but sub level stays constant (computed independently from `masterGain`). This agent adds: (1) a **loudspeaker mix slider** (±10 dB) applied to main speaker channels after DBAP, (2) a **sub mix slider** (±10 dB) applied to subwoofer channels after LFE routing, and (3) a **focus auto-compensation toggle** that auto-updates the loudspeaker slider when focus changes. Both sliders are post-DBAP, pre-output, atomic, and GUI/CLI controllable at runtime.
- **Threading and Safety Agent:** Oversees the multi-threading model and ensures real-time safety. It defines how threads (audio callback thread, streaming thread, control thread, GUI thread, etc.) interact and shares data, using lock-free queues or double-buffering to maintain synchronization without blocking.
- **Backend Adapter Agent:** Abstracts the audio hardware or API (e.g., CoreAudio, ASIO, ALSA, PortAudio). It provides a unified interface for the engine to output audio, handling device initialization, buffer callbacks or threads, and bridging between the engine’s audio buffers and the OS/hardware.
- **GUI Agent:** Handles the graphical user interface and user interaction. It displays system state (levels, positions, statuses) and allows the user to adjust parameters (e.g., moving sound sources, changing volumes, selecting output device) in a way that’s safe for the real-time engine.

Each agent has its own detailed document (located in `internalDocsMD/realtime_planning/agentDocs/`) describing its role, constraints, and interfaces in depth. Developers responsible for each component should refer to those documents for implementation guidance.

## Data Flow and Interactions

The spatial audio engine’s processing pipeline flows through these agents as follows:

1. **Input Stage (Streaming):** Audio sources are ingested by the **Streaming Agent** (from files or streams). Decoded audio frames for each source are buffered in memory.
2. **Control Updates:** Concurrently, the **Pose and Control Agent** receives updates (e.g., new source positions, user commands) and updates a shared scene state. This state includes each source’s position and orientation, as well as global controls like mute or gain changes.
3. **Audio Callback Processing:** On each audio callback (or frame tick):
   - The **Spatializer (DBAP) Agent** reads the latest audio frame from each source (provided by the Streaming agent via a lock-free buffer) and the latest positional data (from Pose and Control agent’s shared state). It calculates the gain for each source on each speaker using the DBAP algorithm and mixes the sources into the spatial audio output buffer (one channel per speaker output).
   - The **Compensation and Gain Agent** applies post-DBAP mix trims to the internal render buffer before copying to output: a loudspeaker mix multiplier to all non-subwoofer channels, and a sub mix multiplier to subwoofer channels. If focus auto-compensation is enabled, the loudspeaker mix is automatically adjusted when `focus` changes to compensate for DBAP's reduced total power at higher focus values.
   - As part of the mixing process, the **LFE Router Agent** extracts low-frequency content. For example, it might low-pass filter the summed signal or individual source channels and send those frequencies to a dedicated LFE output channel. If a source is flagged as LFE-only, this agent routes that source’s content directly to the subwoofer channel.
   - After sources are mixed into a set of output channels (including the LFE channel if present), the **Output Remap Agent** takes this intermediate multichannel output and reorders or downmixes it according to the actual output configuration. For instance, if the engine’s internal spatial layout is different from the sound card’s channel order, it swaps channels as needed. If the output device has fewer channels than produced (e.g., rendering a multichannel scene on stereo output), it downmixes appropriately (with pre-defined gains to preserve balance).
4. **Output Stage:** The **Backend Adapter Agent** interfaces with the audio hardware or API. It either provides the engine’s output buffer directly to the hardware driver or calls the system’s audio callback with the mixed/remapped audio. This agent handles specifics like buffer format (interleaved vs planar audio), sample rate conversion (if needed), and ensuring the audio thread meets the API’s timing requirements.
5. **User Interface Loop:** In parallel with the audio processing, the **GUI Agent** runs on the main/UI thread. It fetches state (e.g., current source positions, levels, streaming status) in a thread-safe manner (often via copies or atomics provided by other agents) and presents it to the user. When the user interacts (for example, moving a sound source in the UI or changing master volume), the GUI Agent passes those commands to the relevant agents (Pose and Control for position changes, or Compensation and Gain for volume adjustments, etc.) without directly interfering with the audio thread.

This data flow ensures that heavy I/O (disk or network reads, GUI operations) and control logic are offloaded to separate threads, while the time-critical audio mixing runs on the dedicated real-time thread. Communication between threads is handled by shared data structures that are updated in a controlled way.

## Real-Time Considerations

Real-time audio processing imposes strict constraints that all agents must respect for the system to function without audio dropouts:

- **No Blocking Calls in Audio Thread:** The audio callback (Spatializer and subsequent processing) must never wait on locks, file I/O, network, or any operation that could block. Agents like Streaming or GUI must use double-buffering or lock-free queues to deliver data to the audio thread, so the audio processing can run without pausing:contentReference[oaicite:1]{index=1}.
- **No Dynamic Memory Allocation in Callback:** All memory required for audio processing should be pre-allocated. For example, audio buffers for mixing and any filter coefficients should be initialized ahead of time. This avoids unpredictable delays from memory allocation or garbage collection during the audio loop.
- **Time-Bound Processing:** Each audio callback must complete within the allotted frame time (e.g., a few milliseconds). Algorithms used (such as the DBAP calculations, filtering for LFE, etc.) should be optimized (using efficient math and avoiding overly complex operations per sample). Worst-case execution time must be considered, especially when the number of sources or speakers scales up.
- **Thread Priorities:** The audio processing thread (or callback) should run at a high priority or real-time scheduling class as allowed by the OS. Background threads (streaming, control, GUI) run at lower priorities to ensure the audio thread isn’t starved of CPU time. The Threading and Safety agent will outline how to set this up and avoid priority inversions.
- **Synchronization Strategy:** Shared data (like source positions, audio buffers) is synchronized in a lock-free manner. For example, the Pose and Control agent might maintain two copies of the positions and atomically swap pointers to publish new data to the audio thread, or use atomics for small updates. The goal is to eliminate heavy locks in the audio path while still keeping data consistent.
- **Buffering and Latency:** The Streaming agent should keep a small buffer of audio data ready in advance (e.g., a few blocks) so that momentary disk or network delays don’t cause underruns. However, excessive buffering adds latency, so a balance is required. Similarly, any control or GUI commands that need to take effect (e.g., mute or move source) should be applied at frame boundaries to maintain sync.

All agents must cooperate under these constraints. If any agent fails to meet real-time requirements (for instance, if decoding audio takes too long, or a lock is held too long), the whole system can suffer an audible glitch. During development, agents should test under stress conditions to ensure timing stays within limits. Logging in the audio thread should be minimal or absent (since I/O can block); use lightweight telemetry (e.g., atomic counters or ring buffers for logs) if needed to diagnose issues without hurting performance.

## Development and Documentation Notes

This master document and the individual agent documents are living plans for the implementation. As development progresses:

- **Maintain Consistency:** Developers should keep the design aligned across documents. If an interface between agents changes, update both this overview and the respective agent docs to reflect it.
- **Progress Updates:** Each agent lead should update `internalDocsMD/agents.md` (the central index of agents) with status and any noteworthy changes. For example, mark when an agent is implemented or note decisions that affect other agents.
- **Cross-Referencing:** Ensure that references to code (e.g., `SpatialRenderer.cpp`, `mainplayer.cpp`) remain accurate. If code structure changes (like files are renamed or new helper classes are created), update the documentation accordingly.
- **Rendering Pipeline Documentation:** If the processing pipeline is modified (for instance, adding a new processing stage or altering the order of operations), update the global `RENDERING.md` document. This ensures our real-time audio rendering approach is clearly recorded for future maintainers.
- **Parallel Development Coordination:** Given that agents are being implemented in parallel, schedule regular sync-ups to discuss integration points. Use this document as a guide to verify that all assumptions (data formats, call sequences, thread responsibilities) match across agents.

By following this plan and keeping documentation up-to-date, the team can build a robust real-time spatial audio engine. This overview will serve as a roadmap, and each agent’s detailed document will provide the specific guidance needed for individual implementation and eventual integration into a cohesive system.

**OSC port policy:** use a **fixed localhost port (9009)** for the engine `ParameterServer`.
This is simplest for the prototype, but may conflict if multiple instances run or the port is occupied.
GUI must surface clear errors; future refactor can add configurable/auto-pick ports.
