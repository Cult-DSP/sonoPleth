
```markdown
# GUI Agent

## Overview
The **GUI Agent** is responsible for the graphical user interface of the real-time spatial audio engine, enabling users (or developers during testing) to visualize the state of the system and interact with it in real time. This includes displaying information such as active audio sources, their positions, audio levels (meters), and system status, as well as providing controls to adjust parameters (like moving sources, changing volumes, selecting output devices, toggling settings like mute or spatialization modes).

The GUI Agent is not part of the audio processing pipeline, but it runs in parallel on the main application thread (or a dedicated UI thread, depending on the framework) and must communicate with the audio engine safely. It serves as the human interface to the complex operations going on under the hood, and thus its design focuses on clarity, responsiveness, and non-intrusiveness to the audio thread.

## Responsibilities
- **Visualization of Spatial Scene:** Present a visual representation of the audio scene. For instance, it may show a top-down or 3D view with icons for each sound source and possibly the listener. As sources move (updated by the Pose and Control agent), the GUI should update their positions on screen. This helps in debugging and tuning spatial placement.
- **Level Meters and Status Indicators:** Provide real-time level meters for outputs (and possibly per source) so one can see audio activity. Also indicate system status like buffer underruns (e.g., a red indicator if the audio thread ever underruns), CPU usage of audio thread, etc. These indicators help in optimizing and ensuring real-time performance is maintained.
- **Control Widgets:** Allow user to perform actions:
  - Move sources by dragging icons (which sends new coordinates to the Pose and Control agent).
  - Add or remove sources (maybe a button to load an audio file, which would engage Streaming agent and Pose agent).
  - Adjust per-source gain (sliders), or mute sources.
  - Master volume control (slider or knob tied to Compensation and Gain agent).
  - Toggle LFE on/off or other mode switches (which would inform LFE Router or compensation if needed).
  - Select audio output device or channel configuration (drop-down to trigger Backend Adapter to switch devices).
  - Possibly enable/disable spatialization (like a bypass mode to compare).
- **Logging and Debug Info:** Display logs or textual info for debugging. If the engine has a logging mechanism capturing events (like “source X buffer underrun” or “position updated”), the GUI might have a console or status box to show these. It should retrieve such logs via a thread-safe method (perhaps reading from a log buffer populated by the engine).
- **Agent Progress/Status UI (for development):** Since multiple agents are being built in parallel, the GUI could have a developer-only section that shows what each agent is doing (like “Streaming: X buffers ready”, “Pose last update 16 ms ago”, etc.). This isn’t necessary for final product but can assist development. The GUI Agent might facilitate this by providing an interface to query each agent’s status (via function calls that are safe, e.g., reading atomic counters).
- **Handoff for Future**: The GUI also acts as a place for documentation in action – showing the features. Ensure the GUI is designed so that a future team can easily understand how to use the engine through the GUI controls.

## Relevant Internal Files
- **`EngineGUI.cpp` / `.h`:** The implementation of the GUI agent. If using a library like Qt, this could be where the QMainWindow is defined and UI elements are set up. If using ImGui (for a quick debug UI), this would contain the drawing code.
- **`mainplayer.cpp`:** Often, the main function will instantiate the GUI as part of the application. It might create an instance of EngineGUI and run the UI loop. It also connects GUI events to engine calls.
- **`ControlInterface.h`:** Perhaps an abstraction that GUI calls to effect changes in the engine. For example, a function `EngineController::moveSource(id, newPos)` that the GUI triggers when a user drags a source. This would be implemented by, say, posting a command to the Pose agent. This interface decouples the GUI code from direct agent manipulation and ensures thread safety.
- **`internalDocsMD/agents.md`:** Not code, but the GUI agent might link to or be documented in relation to that. Possibly a developer could open a help dialog that references the documentation or agent responsibilities (for developer builds).

## Hard Real-Time Constraints
The GUI Agent itself does not run on the real-time audio thread, but it heavily interacts with data that originates from that thread. Thus:
- **Non-Blocking Engine Queries:** The GUI must never directly call something on the audio thread that could block it. It should only access engine state through safe copies or asynchronous mechanisms. For example, if it wants the current level of a channel, the audio thread might periodically store that level in an atomic variable or ring buffer, and the GUI reads from there. The GUI should **never** lock a mutex that the audio thread might also need, to avoid priority inversion.
- **Thread Separation:** Typically, GUI frameworks have their own thread (the main thread) separate from audio. Communication should use the Threading agent’s patterns: e.g., use an atomic or a lock-free message queue for commands. The Pose and Control agent likely provides thread-safe functions to update positions which internally use a queue or double buffer.
- **Refresh Rate vs Audio Rate:** GUI can operate at a much lower rate (e.g., 30-60 FPS for visuals, or even updating text a few times per second). It doesn’t need to update every audio frame. This means the GUI should throttle how often it polls engine state. For instance, a timer could trigger GUI updates at 60Hz. In each update, it reads the latest available metrics from the engine. This prevents excessive overhead or contention (and is enough for human eyes).
- **Avoid Heavy Processing on GUI thread that starves audio thread:** If the GUI does something heavy (like loading a large file or computing a waveform display), it might tax the CPU. Since the audio thread is separate and high priority, that’s usually okay, but if CPU is maxed out, even a high-priority thread can struggle. So be mindful: possibly do heavy GUI computations in a worker thread as well, keep main thread responsive. This is more of general app performance than strict real-time rule, but it affects the perception of performance.
- **Synchronous vs Asynchronous Commands:** When user triggers something (like adding a source), the GUI will call into engine control. The actual act might happen on control thread asynchronously. GUI should give immediate feedback (like show the source on UI) even if engine is processing it; but also handle if engine says “failed to add source” etc. The main thing: don’t wait in the GUI for a long operation on audio side; instead fire-and-forget and update GUI when confirmation comes if needed.

## Interaction with Other Agents
- **Pose and Control Agent:** The GUI’s primary link for interactive spatial controls. When the user drags a source icon, the GUI should call a function to update that source’s position. The Pose agent will handle it safely (queuing the new position and applying it). Conversely, when sources move (maybe via an automation or script), the Pose agent updates the scene and the GUI should reflect it. The GUI might periodically poll the positions from Pose (which could be reading the same scene state the audio uses, but in a thread-safe snapshot way). Alternatively, the Pose agent could emit events that GUI can catch (depending on how event-driven we make it; polling is simpler to implement).
- **Streaming Agent:** GUI may allow adding a new audio stream (like a “Open File” dialog). When a file is chosen, the GUI triggers the Streaming agent to load it (probably via Pose/Control as well, since adding a source involves position too). Also, the GUI might display streaming status, e.g., how many seconds of audio buffered or if a stream ended. The Streaming agent might provide status info (like “buffer % full” or “at EOF”) through a safe query. The GUI should check those maybe every second or on user request. If a stream error happens (file not found or decode error), Streaming agent should signal that (maybe via a callback or status flag) and GUI should show an error message.
- **Spatializer & Levels:** For level meters, the Spatializer (or compensation agent at output) can provide current RMS or peak levels for channels. Possibly the audio thread calculates these and stores in a global atomic array, which the GUI reads. Or the GUI could request them periodically via a thread-safe call. It's easiest if audio thread just updates a global atomic of levels (which is write in audio, read in GUI, safe as long as atomic or coarse grain sync). The GUI agent then uses those to draw VU meters for each channel (speakers, LFE).
- **Compensation and Gain Agent:** GUI volume slider manipulates master gain in Compensation agent. So when user changes the slider, the GUI should call something like `setMasterGain(x)` that the Compensation agent exposes (through control thread). Similar for per-source gain sliders (which might tie to Pose/Control or directly to Compensation’s data if accessible via control).
- **LFE Router and Output Config:** If there's a checkbox for "Enable LFE bass management" or selection for "Speaker config: Stereo vs 5.1", those would cause messages to LFE Router or Backend Adapter respectively. The GUI might disable LFE toggle if in stereo mode (since no LFE channel).
- **Backend Adapter Agent:** If user selects a different audio device or output mode, the GUI calls into the Backend Adapter (or a high-level engine function that wraps it) to switch. The adapter will handle the actual device change, possibly requiring reinit. The GUI should handle the transition gracefully (maybe disable controls for a moment or indicate loading). If device selection fails, adapter returns an error and GUI should show a message.
- **Threading and Safety Agent:** The GUI heavily relies on the patterns set by the Threading agent. It will use the lock-free queues or double buffers to send and receive data. For example, if there's a log queue (audio thread pushes, GUI pops), that structure came from Threading agent guidelines. The GUI dev needs to coordinate to ensure using them correctly. Also, if using any locks in GUI code, make sure they don't conflict with audio thread locks (ideally no locks that audio holds at all).
- **Master Document and Agents Doc:** The GUI can indirectly support the documentation by giving an overview of what's active. Perhaps beyond scope, but maybe a “Help->About” could list agent responsibilities (from realtime_master.md), which ironically is the content we’re writing. For now, ensure that the GUI agent’s behavior as described is consistent with what other agents expect (we should double-check each agent doc to ensure any GUI references align).

## Data Structures & Interfaces
- **UI Components References:** Buttons, sliders, canvas for scene, etc. If using a specific GUI toolkit, list the main components. E.g., `QGraphicsView` for the scene, with `SourceItem` objects; `QSlider` for volume, etc. Or if using ImGui, then not as formal structures, but we have state variables for each control.
- **Engine Controller Interface:** Perhaps a singleton or central object that the GUI calls to interact with the engine. For instance, `EngineController` with methods: `addSource(file, position)`, `removeSource(id)`, `setSourcePosition(id, pos)`, `setSourceGain(id, gain)`, `setMasterGain(val)`, `toggleLFE(bool)`, `selectDevice(deviceId)`, etc. Internally, those would package commands for the respective agents. This decouples the GUI code from low-level details and ensures thread-safe usage if `EngineController` implements the proper locking or queuing (likely it will push tasks to Pose thread or main).
- **Data polling structures:** e.g., `std::atomic<float> channelLevels[MAX_CHANNELS]` updated by audio thread for meters. Or an atomic copy of source positions for GUI (though positions could be read from the shared scene directly if locked appropriately, or double buffered scene can be used).
- **Event Queue for Logs:** If implemented, a lock-free queue of strings for log messages (with a size limit). GUI pops and displays them in a text box.
- **GUI Refresh Timer:** Not exactly a data structure, but a mechanism (like QTimer or a loop in ImGui) that triggers `updateGUI()` periodically to redraw and poll new data. Ensure it runs on GUI thread and doesn’t conflict with engine threads.
- **Mapping between GUI elements and engine entities:** e.g., if each source has a GUI object, it likely stores the source ID so when user clicks it, we know which source to move. That mapping must be maintained as sources are added/removed (update when Streaming/Pose confirm a new source is active or a source ended).
- **Thread Safety Helpers:** Possibly use Qt’s thread-signal mechanism (e.g., signals/slots queued connections ensure thread separation) if applicable. Or implement our own safe callback (like GUI registers a callback function that Pose thread calls when state changes – but that can be tricky if not careful). The simpler approach is GUI polls needed info, which avoids complicated thread events.

## Development and Documentation Notes
While implementing the GUI Agent:
- **Consistency with Engine State:** Keep in mind the information flow. Document in this file how the GUI obtains each piece of info:
  - “Source positions are updated by reading from Pose and Control’s scene state every 50ms.”
  - “Level meters read atomic channelLevels set by Compensation agent every frame.”
  - This clarity will help if GUI values seem off – devs know where it’s coming from.
- **User Experience Considerations:** Although this is an internal tool, mention any notable UX decisions. For example, “dragging a source sends continuous position updates (throttled maybe) so audio moves smoothly” or “volume slider is logarithmic scale because perceived loudness is logarithmic” – whatever is relevant.
- **Parallel Dev Coordination:** If some parts of GUI depend on other agents being ready (like level metering requires Compensation to produce data), coordinate when those will be done. Possibly stub out features until core engine parts are ready. Note in this doc what is stubbed or planned: e.g., “VU meters currently use a dummy value until the engine provides real levels.”
- **Testing the GUI:** Outline how to test that GUI controls effectively change engine state. For example, if one moves a source on GUI, check that you hear the audio pan accordingly; if master volume slider is down, audio silences, etc. Also test performance – open debug overlay to ensure GUI doesn’t consume too much CPU (should be fine though).
- **Documentation and Handoff:** Ensure any new controls introduced are also described in the user/developer documentation. For instance, if a toggle for a spatialization mode is added, update RENDERING.md or relevant docs to explain what that mode does (if it's an internal debug feature, document it here).
- **Update Master Doc if needed:** The master doc mentions the GUI agent broadly. If our implementation adds specific capabilities (like a monitor for XRuns), consider adding that detail if useful. But likely fine as is.
- **Maintaining Thread Safety:** This is a key area where issues can creep in. Document any assumptions, like “We assume atomic read of a float is fine for level meter (some tiny risk of tearing on 32-bit float on 64-bit system, but it's atomic if aligned). Alternatively, double buffer the level values if needed for absolute safety.” If any such decisions are made, note them for future maintainers.

The GUI Agent, by following these guidelines and staying in sync with the rest of the engine, will greatly enhance the ability to work with and demonstrate the real-time spatial audio engine, all while maintaining the strict performance requirements of the system.