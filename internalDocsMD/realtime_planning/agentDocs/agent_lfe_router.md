# LFE Router Agent

## Overview

The **LFE Router Agent** is responsible for managing low-frequency effects (LFE) channel content within the spatial audio engine. The LFE channel (often referred to as the “.1” in a 5.1 or 7.1 system) is a dedicated channel for bass frequencies, typically played through a subwoofer. This agent ensures that deep bass content is properly directed to the subwoofer channel without overwhelming or distorting the main speakers, and that any content meant exclusively for the LFE is handled appropriately.

In this engine’s pipeline, the LFE Router operates after the initial spatial mix (performed by the Spatializer) but before final output mapping. It can both **extract** low-frequency components from main channels (bass management) and **insert** dedicated LFE signals (if certain sources are flagged to go directly to LFE). The outcome is a composite multi-channel output where the LFE channel carries the intended low-frequency audio, enhancing the impact of effects like explosions or musical bass, while the main channels are relieved of those frequencies.

## Responsibilities

- **Bass Extraction (Bass Management):** If the system is configured to redirect bass, the LFE Router will filter low-frequency content from the main speaker channels and send that to the LFE channel. This typically involves applying a low-pass filter (e.g., cutoff around 80 Hz, configurable) to either each main channel or the combined mix, so that frequencies below the cutoff are summed into the LFE. The main channels might optionally have those frequencies reduced to avoid double-dipping (depending on whether the speakers are full-range or not).
- **Dedicated LFE Signal Handling:** Some audio content might be specifically intended for the LFE (for example, an action movie might have a dedicated LFE track with rumbles). If our engine supports marking certain sources or effects as LFE-only, this agent routes that content exclusively to the LFE output. It ensures that such content bypasses spatialization on main speakers (since subwoofer content isn’t directional).
- **Filtering and Phase Alignment:** Apply appropriate filtering with minimal phase issues. For instance, use filters that maintain phase coherence between what’s left in mains and what’s sent to sub, to avoid cancellations or reinforcements at crossover frequencies. In development, a simple IIR low-pass might be used for efficiency, but be mindful of the phase; consider using the same cutoff for a complementary high-pass on mains if doing bass management.
- **Level Calibration:** Possibly adjust the LFE channel gain to match system calibration. In many setups, the LFE channel is dialed about 10 dB hotter than mains (as per film standards) or has some calibration offset. The LFE Router may apply a gain factor to the generated LFE signal to conform to such standards. It should also avoid clipping – summing multiple channels’ bass might require scaling down.
- **Bypass or Mode Control:** Provide the ability to bypass LFE routing if not needed (e.g., in a headphone or stereo rendering scenario, or if the user disables bass management). The agent should detect or be informed of whether an LFE channel is present in the current output layout. If not, it should do nothing (or possibly downmix bass into the main channels if mixing to stereo – though usually if no sub, full-range mains handle bass, so you might _not_ remove it). Essentially, adapt its behavior to the output format.

## Relevant Internal Files

- **`SpatialRenderer.cpp` (or `MixEngine.cpp`):** The actual audio processing code might include LFE handling. Possibly within the main loop after spatialization, there could be calls to an LFE handling function. If the LFE logic is complex, it could be factored out into its own source file (e.g., `LFERouter.cpp`), but initially it might live alongside the mixing code.
- **`LFERouter.h` / `.cpp`:** If separated, these files would contain the filtering implementation and routing logic. For instance, a method `processLFE(float** channels, int numChannels, float* lfeOutput, int numFrames)` that takes the multichannel buffer and produces the LFE channel content.
- **`SpeakerLayout.h` or config files:** Information about whether an LFE channel exists and perhaps the crossover frequency might come from configuration. For example, a JSON or config might specify “useLFE: true, lfeCutoff: 80Hz”. The LFE Router would reference these settings.
- **`RENDERING.md`:** The overall rendering document likely describes how the LFE fits in. This agent’s behavior should align with that documentation. If RENDERING.md already has a section on bass management or LFE, ensure consistency.

## Hard Real-Time Constraints

The LFE Router runs as part of the real-time audio processing pipeline, so it must meet the same strict timing and safety requirements:

- **Efficient Filtering:** The low-pass filtering (and any high-pass on mains if done) must be computationally light. Typically a simple biquad filter per channel or a single combined filter is used. For example, implementing a second-order Butterworth low-pass per channel at 80 Hz is quite fast. Avoid using heavy convolution or linear-phase FIRs in real-time unless absolutely needed, as those could introduce latency or high CPU usage.
- **No Dynamic Memory or Delays:** All filter states (history samples, coefficients) should be pre-allocated. Processing each frame should just involve a few multiply-add operations per sample for the filter – no allocations, no locks. If using an algorithm that requires chunking data (like an FFT for low frequency extraction), be cautious: an FFT would add latency and complexity, so likely stick to time-domain IIR filtering.
- **Bounded Time Complexity:** Processing should scale roughly O(N) with the number of channels and sources. In worst case, if filtering each main channel individually, that’s M (channels) _ frameSize operations for the filter, which is fine. Summing into LFE is another O(M _ frameSize) for addition. These are linear and should be manageable. Ensure no algorithmic surprises (like an adaptive filter tuning or something weird).
- **Avoid Phase-heavy computation in RT:** If more advanced techniques are considered (like phase alignment or delay compensation to align sub and mains), be careful implementing anything that might involve lookahead or delay in the realtime thread. Simpler is better in the callback – we can accept a small phase discrepancy if needed rather than over-complicate here.
- **Testing for Glitches:** Filter algorithms can sometimes blow up (e.g., if coefficients are NaN due to bad design or if they require initialization). Make sure to initialize filter states properly and handle extreme cases (like DC input). Ensure stability of the filter (design it with stable coefficients). During development, test with known signals to ensure no ringing or pops when switching LFE routing on/off. Also ensure the agent doesn’t produce denormalized floats (use flush-to-zero if needed for very low signals, as denormals can slow down DSP significantly).

## Interaction with Other Agents

- **Spatializer (DBAP) Agent:** The LFE Router receives the output of the Spatializer. Typically, the Spatializer will output the full-band signals for each main speaker channel (and possibly nothing in the LFE channel). The LFE Router then processes those signals:
  - If bass management is on, it will tap those main channels, apply low-pass filtering, and accumulate the bass into the LFE channel.
  - It might also reduce the bass in the main channels correspondingly (applying a high-pass filter or an EQ dip) if needed to avoid duplication. The interaction needs clarity: either the Spatializer outputs full-range and LFE Router handles both extraction and possibly removal of bass from mains, **or** Spatializer could intentionally output limited bandwidth to mains expecting LFE Router to carry the low end. The simpler approach: let Spatializer do full-range, and LFE Router will just duplicate low frequencies to LFE (for additive bass management). If doubling is an issue, the calibration could handle it or a slight cut in mains can be applied.
- **Streaming Agent:** If a source is flagged as LFE-only (like a special effect track with no spatial position), the Streaming Agent would still provide the audio, but likely the Pose/Control agent or source metadata marks it as LFE. The LFE Router should look at source metadata (provided by Pose/Control or Compensation perhaps) to determine that a given source’s content should be routed entirely to LFE. It might intercept that either by the Spatializer skipping that source (not mixing it into mains) and handing it over to LFE Router, or by Spatializer mixing it somewhere that LFE Router knows to pick up. In practice, easier: Pose and Control could create a “virtual speaker” that is the LFE and Spatializer would pan that source only to LFE. But if Spatializer doesn’t handle LFE, then LFE Router must take the source’s audio separately. Coordination here: possibly easier for Spatializer to ignore LFE sources, and Streaming/Control to feed those directly to LFE Router.
- **Pose and Control Agent:** This agent might inform LFE Router which sources or what content should be treated as LFE. For example, it could tag a source as `source.lfe = true`. LFE Router needs access to that information. Could be via a flag in the scene data or a separate list of LFE sources. Also, if the user or scene dynamically toggles bass management (maybe a user setting in GUI to turn on/off subwoofer routing), Pose/Control or GUI would signal that to LFE Router (or to a global state that LFE Router reads). So there is some control interface for enabling/disabling or adjusting the crossover frequency that Pose/Control/GUI might mediate.
- **Output Remap Agent:** The LFE Router’s output becomes one of the channels that Output Remap will handle. If the output device has a physical LFE channel, Output Remap will map the LFE buffer to that channel. If the output is stereo (no LFE), Output Remap might need to downmix the LFE content into the mains (if we choose to support that). Alternatively, the LFE Router itself could detect “no LFE channel in output” and therefore not produce a separate LFE buffer, possibly merging it to mains to preserve bass. The division of responsibility between LFE Router and Output Remap should be decided: likely LFE Router just produces LFE channel if one is configured, else does nothing; Output Remap will handle any format conversion.
- **Compensation and Gain Agent:** There might be calibration gains involved – e.g., if the sub needs +10 dB gain relative to mains for reference, the Compensation agent might supply that or apply it. The LFE Router might simply produce content at unity and rely on Compensation to adjust LFE channel gain. Alternatively, LFE Router could apply the gain. Coordination: decide where to apply LFE-specific gain trims. Probably simpler to include in LFE Router for now if needed. Also, if the engine has any dynamic EQ or compression on the LFE (sometimes used to tame extreme spikes), that could be considered part of either LFE Router or Compensation. At this stage, likely out of scope, but leave a note if needed.
- **Threading and Safety Agent:** The interactions above require some configuration data (like flags for LFE mode or source tags). Access to those must be thread-safe. For instance, the Pose agent might update a source’s “isLFE” flag while the audio thread is running. If that’s an atomic bool or part of the double-buffered scene state, then the LFE Router reading it in real-time is fine. Also, if the LFE filter has state that might be reset or changed (like new coefficients for a different cutoff), that should be done carefully not to conflict with processing (e.g., update filter coefficients between blocks or using atomic swap of filter parameters).
- **Backend Adapter Agent:** Not directly, but the Backend ultimately needs to know the audio stream has an LFE channel. That is likely configured by the Output Remap or main engine when setting up the device (e.g., telling the sound API we have 6 channels for 5.1). The LFE Router just ensures that channel’s content is appropriate.

## Data Structures & Interfaces

- **Filter State:** For each channel being filtered (main channels for bass extraction, and possibly LFE channel if any smoothing needed), maintain filter state (previous inputs/outputs). E.g., a struct for a biquad filter with coeffs {b0,b1,b2,a1,a2} and state {z1,z2} for each channel. These would be small and possibly stored in an array indexed by channel for convenience.
- **Coefficients Management:** The filter coefficients (for low-pass and high-pass if used) should be computed at initialization (based on a set cutoff frequency and sample rate). If runtime adjustment is needed (say user changes crossover freq), have a method to recalc coeffs and update them safely between audio frames.
- **Routing Flags:** Possibly a simple array or list of booleans for each source or channel indicating if it’s LFE content. For example, an array `isSourceLFE[MAX_SOURCES]`. The Pose/Control agent or streaming could mark entries in this. The Spatializer might consult it to skip mixing those to mains. The LFE Router could consult it to know to add those sources fully to LFE (though if Spatializer skipped them, the LFE Router must still get their audio – maybe the Streaming agent can feed them into a special LFE buffer? Alternatively, simpler: treat them as normal sources but position them at an “LFE speaker” which only feeds sub, if the Spatializer can handle a virtual sub channel).
- **Audio Buffers:** The LFE Router will operate on the array of output channels after spatialization. So it might have:
  - Input: pointer to array of channel buffers (size M for mains) filled by Spatializer.
  - Output: the LFE channel buffer (which might be one of the array elements if we allocate M+1 channels for convenience).
  - Alternatively, it could produce LFE in a separate buffer and then attach it to the output list.
  - For implementation, perhaps the Spatializer yields an output with M (mains) channels and leaves the LFE channel buffer zeroed; LFE Router then fills that extra channel.
- **Methods/Interfaces:** A function like `applyLFERouting()` that is called from the audio processing pipeline after spatialization:
  - It takes the mixed audio buffers for main channels and the empty LFE buffer.
  - It iterates through each sample:
    - For each main channel, run it through a high-pass filter (if removing bass from mains is desired) – replace the sample in the main buffer with the filtered output.
    - Simultaneously accumulate a low-pass filtered version of that sample into the LFE buffer (i.e., LFEbuffer[n] += lowpass(mainChannel[n])).
  - Or do filter per channel and sum: either way ends up similar. If doing per channel low-pass then sum, note that summing can increase level, watch out for that.
  - If any source is exclusively LFE: possibly the Spatializer left its output in a separate buffer or we handle separately. For now, assume if a source is LFE-only, Spatializer put its signal into LFE channel directly or we handle via separate logic.
- **Crossover Config:** Store cutoff frequency and perhaps filter type (order, etc.). Possibly in a config struct or constants at top. This might be adjusted via control agent if needed.

## Development and Documentation Notes

When implementing the LFE Router Agent:

- **Decide on Bass Management Strategy:** Clearly document here whether we are doing _additive bass_ (leaving bass in mains and duplicating to sub) or _redirected bass_ (removing from mains and moving to sub). This affects frequency response. Many consumer systems do additive at device level, but in production, you might do redirected to avoid doubling. Choose one and note the rationale.
- **Document Filter Details:** Note the filter design (cutoff frequency, filter order, type). For example, “Using a second-order Butterworth low-pass at 80 Hz for bass extraction. Mains are left full-range (additive bass to sub)” or “Using Linkwitz-Riley 4th order split at 100 Hz, so mains are high-passed, sub low-passed for a flat crossover”. These details should also be summarized in RENDERING.md under output stage.
- **Testing:** Plan tests such as playing a low-frequency tone in one channel and confirming it appears in LFE appropriately, and maybe that phase alignment is acceptable. If possible, test overall frequency response of combined mains+sub to ensure no major dip or bump at crossover. Document any significant test findings or adjustments made (e.g., “Added a 5ms delay to sub to align with mains” if that were needed, or “No delay needed as phase was close enough”).
- **Update Master/Other Docs:** If any change is made to how channels are processed (like deciding to treat LFE sources in Spatializer vs here), update the master overview and the Spatializer doc to reflect that. The team needs a unified understanding of LFE handling. For instance, if we decided Spatializer will include an LFE channel in its output array, make sure Spatializer doc mentions it outputs M (speakers) + 1 (LFE) channels. The master doc should also match that description.
- **Configuration Management:** Note whether LFE is optional. If the system can run with no LFE (like stereo output), ensure the code handles it gracefully (maybe skip filtering). This might be controlled by a config flag or by detecting channel count. Document how to toggle or configure LFE usage (maybe Pose/Control or GUI can set a mode). If not doing now, at least note “Future: add a flag to enable/disable bass management”.
- **Integration with Compensation:** Clarify in documentation if any gain offset is applied. For example, if we decide that the LFE channel should be 10 dB hotter, note if we implement that here (e.g., multiply LFE buffer by 3.16) or if we expect the user or another stage to do it. Since it’s technical, maybe allow configuration; for now might leave unity and rely on external calibration. If nothing is applied, that’s fine but mention that the sub’s level relative to mains is as recorded.
- **Logging/Debug:** It might be hard to “hear” the LFE in normal speakers. Possibly have some debug mode to visualize or monitor the LFE output (like writing it to a file or sending to mains for test). While implementing, such things could be noted but likely removed later. Document any such quirks if they remain in code (e.g., if a debug compile flag outputs LFE to mains for convenience).

By carefully defining its behavior and ensuring alignment with the rest of the engine, the LFE Router Agent will enhance the low-frequency experience in the spatial audio output, all while keeping the real-time performance solid and the integration seamless.
