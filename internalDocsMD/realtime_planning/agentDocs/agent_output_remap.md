# Output Remap Agent

> **Implementation Status: Not started (Phase 7)**
> The **insertion point** for this agent already exists in `Spatializer.hpp`'s
> `renderBlock()` method — the copy loop from `mRenderIO` (internal render
> buffer) to real `AudioIO` output. Currently an identity mapping. When this
> agent is implemented, it will replace that loop with a mapping table (like
> `channelMapping.hpp`'s `defaultChannelMap`) that routes logical render
> channels to physical device outputs.
> See `realtime_master.md` Phase 4 Completion Log for context.

## Overview

The **Output Remap Agent** is responsible for translating the engine’s internal channel layout and format into the format required by the actual audio output device or target environment. In a spatial audio engine, internal processing might use a logical channel order or even a higher channel count than the output. This agent takes the mixed audio from the Spatializer (and LFE Router, etc.) and **reorders, remaps, or downmixes** it so that it matches the physical speaker setup or output mode.

For example, if the internal engine produces 8 channels of audio corresponding to a custom speaker array, but the output device is a standard 5.1 soundcard (6 channels with a defined order), the Output Remap Agent will map the 8 channels to the 6 outputs appropriately (possibly dropping or combining some channels). Another scenario is if outputting to stereo headphones, the agent might downmix the multichannel audio to 2 channels (though for headphones usually a binaural render would replace speaker mixing, but as a fallback or simple mode, a downmix could be used). Essentially, this agent finalizes the channel configuration and format.

## Responsibilities

- **Channel Reordering:** Adjust the order of channels from the engine’s mix to the output device’s expected order. Different APIs and hardware have different channel index orders (e.g., WaveOut might expect 5.1 as L, R, C, LFE, LS, RS, whereas engine might keep L, R, LS, RS, C, LFE or another logical scheme). The agent uses a mapping table or rules to shuffle channel indices so that the correct audio goes to the correct speaker.
- **Channel Count Remapping:** Handle cases where the engine’s output channel count does not match the hardware:
  - **Downmixing:** If the engine has more channels than the output, combine channels. For instance, if rendering a scene over 7.1 internally but output is stereo, the agent will downmix 7.1 to 2.0. This involves summing or averaging certain channels (with appropriate gains, e.g., center mixed equally to L and R, surrounds mixed lower into L and R, LFE possibly mixed into both or omitted based on user preference).
  - **Upmixing/Padding:** If the engine has fewer channels than the hardware (less common, but e.g., engine did stereo but device is a 5.1 interface wanting 6 channels), the agent would route the available channels to some outputs (like copy L to all left channels, R to all right channels, or leave others silent). This scenario might not be typical unless using a fixed interface; but the agent should be aware of it.
- **Format Conversion:** Convert the audio sample format or buffer format if needed. The engine likely works in float planar (separate buffers per channel). The output device might require interleaved samples or a specific data type (e.g., 32-bit integer). While some of this is often handled in the Backend Adapter, the Output Remap Agent can prepare the data accordingly:
  - Interleaving: If needed, take the separate channel buffers and interleave them into one contiguous output buffer frame-by-frame.
  - Sample type conversion: If the backend expects int16 or int32 samples, convert from float to that range (clamping or dithering if necessary). However, if possible, we keep float until the backend to avoid precision loss and do conversion right at output.
- **Mute/Skip Unused Channels:** In cases where certain channels have no corresponding output, ensure they are muted or discarded to avoid spurious audio. Conversely, ensure that any required output channels always have a defined signal (even if silence) so that the hardware doesn’t get unpredictable data.
- **Configuration Loading:** Possibly load or reference a configuration for channel mapping. For custom speaker setups, we might have a config file or user setting describing how internal channels map to device outputs. This agent should reference that. For standard layouts, it can use known defaults.

## Relevant Internal Files

- **`OutputRemap.cpp` / `.h`:** This would implement the logic for remapping. Expect functions like `remapAndFormatChannels(inputBuffers, outputBuffer, config)` that apply the channel mapping and format conversion.
- **`AudioOutputConfig.h`:** A structure or file that defines the output mapping. For example, a mapping array of channel indices or an enum of standard layouts. If the engine supports multiple output modes (stereo, 5.1, 7.1, etc.), this config would describe those.
- **`BackendAdapter.cpp`:** The backend likely works closely with Output Remap. Possibly, the backend calls Output Remap each time to prepare data for the device. In some designs, the backend might contain the remap code. If separated, ensure the interface is clear. E.g., the Backend might provide the destination buffer pointer and expect Output Remap to fill it appropriately from the engine’s internal buffers.
- **`mainplayer.cpp`:** The main application may set up the desired output configuration (maybe via command line or a setting) and initialize the Output Remap Agent accordingly. For instance, mainplayer could read a config saying “use 5.1 output” and set the mapping in the Output Remap agent before starting audio.

## Hard Real-Time Constraints

The Output Remap Agent is part of the final stage of the audio thread, so it must be extremely efficient and real-time safe:

- **Linear Time Operation:** Remapping channels involves memory copies and possibly additions for downmix. This should be O(number of samples \* number of channels). This is straightforward and should be well within the time budget if done with simple loops or `memcpy` for reordering. Downmix adds a bit of math but nothing complex (just adds or averages of samples).
- **No Allocation or Complex Logic:** All mapping logic must use predetermined tables or simple if/else, not dynamic decisions that could allocate. For example, if loading a mapping from config, do that at initialization, not in the audio callback. In the callback, just loop through samples applying the mapping.
- **Use of SIMD:** If available and beneficial, copying or mixing can use SIMD instructions (for instance, interleaving floats might be done 4 at a time). Not required but a potential optimization if profiling shows a bottleneck.
- **Interleaving Overhead:** If the backend requires interleaving, note that this is an extra pass over the data. Ensure this is done efficiently (likely contiguous memory access which is cache-friendly). If performance is an issue, consider whether the Spatializer could output directly interleaved, but that complicates spatialization logic. Probably fine to keep it separate and just ensure the loop is optimized.
- **Thread Safety:** The mapping should not change at runtime without precautions. If the user can switch output mode on the fly, that might involve changing the mapping table. Doing so in real-time must be atomic or happen between callbacks (e.g., stop audio, reconfigure, restart). The Output Remap agent should assume mapping is constant during playback, or if it must change, the Threading agent’s guidance (like double-buffering config) would apply.
- **Testing for Alignment:** Ensure memory alignment if using special instructions or if the audio API has alignment requirements (some APIs require 16-byte aligned buffers for certain operations). Usually float buffers are aligned enough, but just to note.

## Interaction with Other Agents

- **Spatializer (and LFE) Agents:** Output Remap takes the final mixed outputs from Spatializer + LFE Router. For instance, if Spatializer outputs 6 channels (including LFE) internally, those 6 channel buffers are the input. Output Remap knows how to interpret them (e.g., maybe internal order is [LF, RF, LR, RR, C, LFE]) and maps to device. If the Spatializer’s internal channel order or count changes (say adding more speakers), Output Remap must be updated to handle that. Therefore, close coordination: if any change in Spatializer’s output format happens, update the mapping logic. This agent doesn’t change the audio content beyond rearrangement and combination; it just makes sure it matches the output spec.
- **Backend Adapter Agent:** After remapping and formatting, the data is handed to the Backend for actual output. In many cases, the Output Remap might be conceptually part of the backend’s output step. But since it’s separated here, it likely means:
  - The Backend calls Output Remap in its audio callback to get the data in the right form, then sends to hardware.
  - Or the Output Remap is integrated into the audio callback sequence and writes directly into the buffer provided by the audio API.
  - Either way, these two must agree on who allocates the final buffer and who owns it. Possibly the Backend provides an output buffer pointer that Output Remap fills (especially if interleaving and conversion needed).
  - Also, if the Backend changes output device (with different channel count/order), it must update Output Remap’s configuration. So the Backend might call a method like `outputRemap.configure(newDeviceLayout)` outside the audio thread (when device changes).
- **GUI Agent:** The user might have options for output configuration (like selecting stereo vs surround or choosing which physical outputs to use). If so, the GUI via Pose/Control would inform either the Backend or directly the Output Remap agent of the desired mapping. In practice, likely the backend or a higher level handles device selection. But if the engine supports custom routing (like user says “swap left/right speakers”), the Output Remap could expose controls for that. The agent should be ready to accept a new mapping table from a control thread, applying it safely (probably by pausing audio or using double-buffer technique for the mapping).
- **Compensation and Gain Agent:** If any final gain adjustments or mutes per channel are needed (for example, maybe a calibration that one output channel needs -2 dB), this could be applied either in Compensation (which might apply gains on each channel after mixing) or here in Output Remap. This line is fuzzy; likely Compensation would handle uniform gain adjustments and Output Remap stick to structural changes. If the design decides to include per-channel trim in mapping, coordinate with Compensation to avoid duplicating. For now, assume Output Remap is mostly structural (positions of channels), while Compensation covers level tweaks if needed.
- **Threading and Safety Agent:** Ensure that any reconfiguration of Output Remap (like switching mapping) is done in a thread-safe way (e.g., not while audio thread is in the middle of using the old map). This might involve locking out the audio callback briefly or double-buffering the map. The Threading guidelines would help in planning that. At runtime steady-state though, no ongoing thread interaction is needed; it just runs in audio thread.

## Data Structures & Interfaces

- **Channel Mapping Table:** A core structure could be an array that maps from engine channel index -> output channel index. For example, `outputMap[engineChannel] = deviceChannel`. With this, reordering is straightforward: for each engineChannel buffer, we know which device index to place it in. Alternatively, a table of length equal to device channels that says which engine source goes to that output (and possibly with what gain).
  - For downmix, mapping might need gains. E.g., device Left output might get engine Left + 0.7*engine Center + 0.5*engine LeftSurround, etc. This could be a matrix of weights of size [deviceChannels][engineChannels].
  - We could simplify by handling standard cases with hardcoded logic (like known downmix formulas for surround to stereo). But a generalized matrix is flexible. If performance is fine, implementing a fixed small matrix multiplication per frame is okay.
- **Buffer Pointers:** Likely maintain pointers to the current engine output buffers (from Spatializer) and the final output buffer (to device). The Backend or audio system might supply the latter each callback.
- **Format Flags:** Some configuration flags or enums: e.g., `bool interleavedOutput`, `enum OutputSampleFormat { Float32, Int16, ...}`. The Output Remap agent would be configured with these so it knows whether to just copy floats or convert. If interleaved, it loops differently than if planar.
- **Interfaces:**
  - `configureMapping(layoutConfig)`: Set up the mapping table and any downmix coefficients based on a given desired output layout. Call this during initialization or when output changes (not in audio thread).
  - `processRemap(const float* const* engineBuffers, void* deviceBuffer, int frames)`: Perform the remap for `frames` number of audio frames. `engineBuffers` is an array of float pointers (one per internal channel). `deviceBuffer` could be float* if interleaved float output or int16* if converting, etc. Might have multiple overloads or a template for format.
  - Possibly simpler: if the engine and device are both float planar and same channels, this agent might do nothing (identity). It should handle that gracefully (low overhead path).
  - If downmixing: might maintain an internal temp buffer for the downmix process or do it on the fly into the device buffer.

## Development and Documentation Notes

During the implementation of the Output Remap Agent:

- **Define Supported Configurations:** List out which input/output configurations are expected. E.g., internal can be up to 8 channels; outputs may be stereo, quad, 5.1, 7.1. Document how each case is handled (maybe a small table in this doc mapping internal->output for each known layout). This avoids ambiguity and helps testers verify correctness.
- **Document Downmix Rules:** If downmixing, specify the formula. For example: “5.1 to stereo downmix: Left output = L + 0.707*C + 0.707*LS; Right output = R + 0.707*C + 0.707*RS; LFE is optionally mixed equally to both at -10 dB or omitted.” These should align with industry practices if possible. If not sure, at least define something and note it can be adjusted. Put these details in RENDERING.md as well for overall reference.
- **Update Master and Related Docs:** If any changes occurred (for instance, deciding on a particular channel order internally), ensure the master overview and Spatializer doc reflect that same assumption. For instance, if we finalize that internal order is [L, R, C, LFE, LS, RS] for 5.1, all docs should consistently use that in examples. The master doc currently left it abstract; we can update it once decided or ensure consistency when referencing.
- **Integration Testing:** Plan to test the mapping by playing known signals on each channel and verifying they come out of the expected physical speaker. Document any test procedures (like “played pink noise on each internal channel one at a time, confirmed output mapping by listening or measuring”). If any channel was mis-routed, adjust the map and update docs.
- **Performance Check:** Although this is a straightforward step, keep an eye on CPU usage if doing heavy downmix (summing multiple channels). It should be negligible relative to mixing, but if the engine ever supports very high channel counts, we might need to optimize. Document current usage (like “Mapping 8 channels to 2 channels uses 2% CPU of one core at 48kHz”) if possible, just to have a record.
- **Future Considerations:** Note if in the future we might support HRTF/binaural output as a mode, which would bypass this agent (since that’s a different rendering path). Or if we might allow user-defined custom mixes. This agent could be extended in those directions. Keep the design open (like using a matrix approach can generalize to many cases).
- **Coordinate with Backend Developer:** Ensure that the developer handling the Backend Adapter knows what format to expect after remap. For example, if Output Remap handles conversion to int16 interleaved, then the Backend just sends it out. Or if we keep float planar until the backend’s own callback, then the backend will convert. Decide who does conversion and document clearly to not double-convert or leave out conversion accidentally. This doc should note something like “We currently output float32 interleaved to the backend, which then writes to device” or “We convert to int16 here because the chosen API (XYZ) requires int16”.

By thoroughly specifying the channel mapping and ensuring it aligns with both the engine’s internal format and the hardware’s requirements, the Output Remap Agent guarantees that the spatial audio mix is heard correctly by the end user, completing the audio pipeline in a reliable way.
